{"Flutter/Architecture":{"title":"Architecture","links":[],"tags":[],"content":"Reference §\nFlutter 인기 아키텍처 라이브러리 3종 비교 분석 - GetX vs BLoC vs Provider"},"Flutter/index":{"title":"Flutter","links":[],"tags":[],"content":""},"Linux/Kernel-APIs/kernel-↔-user":{"title":"kernel ↔ user","links":[],"tags":["linux","api"],"content":"\n\nput_user(type val, type *address)\n\n#include &lt;asm/uaccess.h&gt;\nstore the value val to user space address address\ntype can be 8, 16, 32, 64 bit (depends on hardware)\n\n\n\nget_user(type val, type *address)\n\n#include &lt;asm/uaccess.h&gt;\nget the value val from user space address address\n\n\n\nunsigned long copy_to_user(void __user *to, const void *from, unsigned long n)\n\n#include &lt;linux/uaccess.h&gt;\ncopy nbytes from kernel-space to user-space\n\n\n\nunsigned long copy_from_user(void *to, const void __user *from, unsigned long n)\n\n#include &lt;linux/uaccess.h&gt;\ncopy n bytes from user-space to kernel-space\n\n\n\n"},"Linux/Kernel-APIs/mknod":{"title":"mknod","links":[],"tags":["linux","api"],"content":"Usage §\nmknod NAME TYPE [MAJOR MINOR]\n\nTYPE: b, c, p, u\nMAJOR: major number\nMINOR: minor number\n\nCreate a character device §\nmknod /dev/zero c 1 5"},"Linux/Kernel-Labs/00_Introduction":{"title":"Introduction","links":[],"tags":[],"content":""},"Linux/Kernel-Labs/03_Character-Device-Drivers":{"title":"Character Device Drivers","links":[],"tags":["linux","kernel"],"content":"Intro §\nUNIX 시스템에서는 모든 장치들을 파일로 취급한다. /dev 디렉토리에는 시스템에 연결된 모든 장치들이 파일 형태로 존재하고, open, write, close, lseek, mmap 등의 시스템 콜을 통해 운영체제에서 device driver로 접근할 수 있다.\nDevice Drivers: Character &amp; Block §\n\n나누는 기준\n\nspeed\nvolume\n시스템과 디바이스 간 데이터 전송 방식 {/* - way of organizing data to be transferred from the device to the system and vice versa */}\n\n\n\nCharacter Device Drivers §\n\n느린 장치들\n적은 양의 데이터를 관리한다.\n데이터에 접근하기 위해서 seek 쿼리를 자주 사용하지 않아도 됨\n주로, 이러한 장치들에서의 Operation(Read, Write)는 Byte 단위로 순차적으로 이루어짐\n예시: 키보드, 마우스, 시리얼 포트, 사운드 카드, 조이스틱 등\n\nBlock Device Drivers §\n\n데이터 볼륨이 큰 장치들\n블록 단위로 데이터를 관리하는 장치들\n검색이 잦은 장치들\n데이터 Block 단위로 Operation이 수행됨\n시스템 콜에 의해 직접 다룰 수 없고, 파일 관리 subsystem과 block device subsystem을 통해 user-space와 block device driver가 소통함\n예시: 하드 디스크, CD-ROM 드라이브, 램 등\n\nMajors and Minors §\n\nMajor: Device Type (IDE disk, SCSI disk, serial port 등)\nMinor: Device Instance (IDE disk 1, IDE disk 2, serial port 1, serial port 2 등)\n\n\nlinux/Documentation/admin-guide/devices.txt에서 모든 Major, Minor 번호를 확인할 수 있다.\n\nls -al $(find /dev -maxdepth 1 -type c) # character devices\nls -al $(find /dev -maxdepth 1 -type b) # block devices\nAllocation §\n\nStatic Allocation\nDynamic Allocation\n\nImplementation Steps §\n1. Create a Device File §\n\n직접 등록\n\nmknod &lt;device_file&gt; &lt;type&gt; &lt;major&gt; &lt;minor&gt;\nmknod /dev/mycdev c 42 0 # character device\nmknod /dev/mybdev b 42 0 # block device\n\n드라이버에서 자동등록\n\nstruct class *cls = class_create(device_name);\ndevice_create(cls, NULL, dev, NULL, &quot;d&quot;); //creates a device and registers it with sysfs\n\nDynamic Minor?\n\n2. Define Character Device Struct §\nstruct my_device_data {\n\tstruct cdev cdev;\n\t// My Data..\n}\n\ncan be accessed by\n\nfile-&gt;private_data\ncontainer_of(inode-&gt;i_cdev, struct my_device_data, cdev)\n\n\n\n3. Registration &amp; Unregistration §\n\nRegistration\n\nint register_cdev(void)\n{\n    int err = register_chrdev_region(MKDEV(MY_MAJOR, 0), MY_MAX_MINORS, &quot;my_device_driver&quot;);\n    if (err != 0) {\n        /* report error */\n        return err;\n    }\n \n    for(int i = 0; i &lt; MY_MAX_MINORS; i++) {\n        /* initialize devs[i] fields */\n        cdev_init(&amp;devs[i].cdev, &amp;my_fops);\n        cdev_add(&amp;devs[i].cdev, MKDEV(MY_MAJOR, i), 1);\n    }\n \n    return 0;\n}\n\nUnregistration\n\nvoid unregister_cdev(void)\n{\n    for(int i = 0; i &lt; MY_MAX_MINORS; i++) {\n        /* release devs[i] fields */\n        cdev_del(&amp;devs[i].cdev);\n    }\n    unregister_chrdev_region(MKDEV(MY_MAJOR, 0), MY_MAX_MINORS);\n}\n4. Implement Operations §\nstruct file_operations §\n\ndefine driver operations\nhttps://elixir.bootlin.com/linux/v6.7.2/source/include/linux/fs.h#L1916\n\nconst struct file_operations my_fops = {\n    .owner = THIS_MODULE,\n    .open = my_open,\n    .read = my_read,\n    .write = my_write,\n    .release = my_release,\n    .unlocked_ioctl = my_ioctl\n};\nOpen &amp; Release §\nRead &amp; Write §\nRead §\n\n\nstatic int my_open(struct inode *inode, struct file *file)\n{\n    struct my_device_data *my_data = container_of(inode-&gt;i_cdev, struct my_device_data, cdev);\n \n    /* validate access to device */\n    file-&gt;private_data = my_data;\n \n    /* initialize device */\n    ...\n \n    return 0;\n}\nWrite §\n\n\nIOCTL §\n\ninput/output control\n\n\nReference §\n\nChar Device API: https://docs.kernel.org/core-api/kernel-api.html#char-devices\nhttps://linux-kernel-labs.github.io/refs/heads/master/labs/device_drivers.html\n"},"Linux/Kernel-Labs/04_IO-access-and-Interrupts":{"title":"I/O access and Interrupts","links":[],"tags":["linux","kernel"],"content":"Objectives §\n\n주변장치와의 소통\nInterrupt Handler 구현\nSynchronizing interrupts with Process Context\n\nIntro §\nBackground Information §\nI/O Ports §\n\nDefinition: set of I/O addresses\ncan be mapped to physical memory addresses → communicate directly with the device through instructions\nport is differentiated by the number of bits: 8, 16, 32 bit ports\nTypes\n\nControl registers: receive device commands\nStatus registers: contains device’s internal status information\nInput registers: data is taken from the device\nOutput registers: data is written to transmit it to the device\n\n\nExample\n\nParallel Port has eight ports (each port: 8bits).\nData Log @base: 0x378\n\nboth entry &amp; exit log\n\n\nStatus Register @base+1: 0x379\nControl Register @base+2: 0x37a\n\n\n\nIRQ (Interrupt ReQuest) §\n\n\nI/O ports or Special memory areas can be insufficient to control the device\n\n\nPolling Inefficiency: interrogating the device status repeatedly\n\n\nObjective: 특정 event가 일어났을 때, hardware가 event가 일어났음을 알려줌\n\n\nTo make use..\n\nInterrupt Handlers must be implemented\nInterrupts must be requested before use and released after use.\nDevice Drivers must\n\nshare an interrupt or\nsynchronize with interrupts\n\n\n\n\n\nAccessing shared resources\n\nbetween an interrupt routine\n\n\n\nAccessing the hardware §\n1. Request Access to I/O Ports §\n\n__request_region\n__release_region\n\n// Shorthand\n#define request_region(start,n,name) __request_region(&amp;ioport_resource, (start), (n), (name), 0)\n#define release_region(start,n) __release_region(&amp;ioport_resource, (start), (n))\nExample §\n\nCOM1\n\nBase Address: 0x3F8\nhas 8 ports\n\n\n\nRequesting access §\n#include &lt;linux/ioport.h&gt;\n \n#define MY_BASEPORT 0x3F8\n#define MY_NR_PORTS 8\n \nif (!request_region(MY_BASEPORT, MY_NR_PORTS, &quot;com1&quot;)) {\n     /* handle error */\n     return -ENODEV;\n}\nReleasing access §\nrelease_region(MY_BASEPORT, MY_NR_PORTS);\nList Port Requests §\n$ sudo cat /proc/ioports\n0000-001f : dma1\n0020-0021 : pic1\n0040-005f : timer\n0060-006f : keyboard\n0070-0077 : rtc\n0080-008f : dma page reg\n00a0-00a1 : pic2\n00c0-00df : dma2\n00f0-00ff : fpu\n0170-0177 : ide1\n01f0-01f7 : ide0\n0376-0376 : ide1\n0378-037a : parport0\n037b-037f : parport0\n03c0-03df : vga+\n03f6-03f6 : ide0\n03f8-03ff : serial\n...\n\n2. Accessing I/O Ports (Kernel Space) §\nasm/io.h §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsignaturecommentsunsigned inb(int port)reads one byte (8 bits) from portvoid outb(unsigned char byte, int port)writes one byte (8 bits) to portunsigned inw(int port)reads two bytes (16-bit) portsvoid outw(unsigned short word, int port)writes two bytes (16-bits) to portunsigned inl (int port)reads four bytes (32-bits) from portvoid outl(unsigned long word, int port)writes four bytes (32-bits) to port\n\nTo insert delay (in case I/O operations transferring data too fast which occurs problems), insert _p such as inb_p, outb_p, etc.\n\nExample §\n#include &lt;asm/io.h&gt;\n#define MY_BASEPORT 0x3F8\n \nunsigned char value = 0xFF;\noutb(value, MY_BASEPORT);\nvalue = inb(MY_BASEPORT);\n3. Accessing I/O ports (User Space) §\nsys/io.h §\n\nioperm\niopl Deprecated\n\nExample §\n#include &lt;sys/io.h&gt;\n#define MY_BASEPORT 0x3F8\n \n// Get &amp; Release permission for the first 3 ports of the serial port\n \n/* 1 to get permission */\nif (ioperm(MY_BASEPORT, 3, 1)) {\n     /* handle error */\n}\n \n/* 0 to release permission */\nif (ioperm(MY_BASEPORT, 3, 0)) {\n     /* handle error */\n}\nInterrupt Handling §\nRequesting an interrupt §\nrequest_irq &amp; free_irq §\n#include &lt;linux/interrupt.h&gt;\n \ntypedef irqreturn_t (*irq_handler_t)(int, void *);\n \nint request_irq(unsigned int irq_no, irq_handler_t handler,\n                unsigned long flags, const char *dev_name, void *dev_id);\n \nvoid free_irq(unsigned int irq_no, void *dev_id);\nhandler function is executed in interrupt context..\n\nwe can’t call blocking APIs(mutex_lock() or msleep())\navoid doing a lot of work &amp; use deferred work if needed\nread the device register to get the status of the device and acknowledge the interrupt\noperations that most of the time can be performed with non-blocking calls\n\nrequest_threaded_irq §\ndevice에서 interrupt 발생해도 non-blocking mode에서 device register 읽을 수 없는 상황 존재..\n이런 경우에 work-in-process action (ex. work queue, kernel thread)를 이용하여 device register에 접근해야 함.\nrequest_threaded_irq 이용하면 process-phase 혹은 interrupt context phase에서 interrupt handling 을 수행할 수 있음.\n\nhandler: interrupt context에서 수행할 function\nthread_fn: process context에서 수행할 function\n\n#include &lt;linux/interrupt.h&gt;\n \nint request_threaded_irq(unsigned int irq, irq_handler_t handler,\n                         irq_handler_t thread_fn,\n                         unsigned long flags, const char *name, void *dev);\nflags §\n\nIRQF_SHARED: interrupt can be shared with other devices.\n\nif not set, if there’s already a handler associated with the requested interrupt, the request for interrupt will fail\nall the associated interrupt handlers will be executed until the device that genet\n\n\nIRQF_ONESHOT:\n\nReference §\n\nrequests_irq\nfree_irq\nProcess Context + Interrupt Context + Context Switching\n\nImplementing an interrupt handler §\nInterrupt Handler Function Signature\nirqreturn_t (*handler)(int irq_no, void *dev_id);\nReference §\nLocking §\n\ninterrupt handler들은 interrupt context에서 실행되기 때문에 다음과 같은 실행 가능한 동작들이 제한된다.\n\nuser space memory 접근 불가\nblocking function 호출 불가\n\n\nspinlock 이용한 synchronization 까다롭고 deadlock 만들 수 있음 (spinlock used is already acquired by a process that has been interrupted by the running handler)\n하지만, spinlock 이용하는 경우 있음…\n\ninterrupt handler - process context 사이에서 데이터 공유\ninterrupt handler - bottom-half handler 사이에서 데이터 공유\n이런 경우에는 interrupt를 끄고 spinlock을 써야됨..\n\n\nDisabling Interrupts\n\nprocessor level에서 모든 interrupt 끄기.. faster &amp; preferred\ninterrupt controller level에서 특정 interrupt 끄기\n\n\n\nDisabling All Interrupts at Processor level §\n#include &lt;linux/spinlock.h&gt;\n \nvoid spin_lock_irqsave (spinlock_t * lock, unsigned long flags);\nvoid spin_unlock_irqrestore (spinlock_t * lock, unsigned long flags);\n \nvoid spin_lock_irq (spinlock_t * lock);\nvoid spin_unlock_irq (spinlock_t * lock);\n\n\nread_lock_irqsave()\n\n\nread_unlock_irqrestore()\n\n\nread_lock_irq()\n\n\nread_unlock_irq\n\n\nwrite_lock_irqsave()\n\n\nwrite_unlock_irqrestore()\n\n\nwrite_lock_irq()\n\n\nwrite_unlock_irq()\n\n\nDisabling Particular Interrupt at Interrupt Controller level §\n\ndisable_irq()\ndisable_irq_nosync(): async version\nenable_irq()\n\nInterrupt Statistics §"},"Linux/Kernel-Labs/05_Deferred-Work":{"title":"Deferred Work","links":[],"tags":["linux","kernel"],"content":"Objectives §\n\nUnderstanding deferred work\nImplementation of common tasks that uses deferred work\nUnderstanding the peculiarities of synchronization for deferred work\n\nBackground information §\nDeferred Work §\n\nDefinition: A class of kernel facilities that allows one to schedule code to be executed at a later timer\nCan run either in process context or in interruption context depending on the type of the deferred work.\nUsed to complement the interrupt handler functionality since interrupts have some important requirements &amp; limitations such as..\n\nThe execution time of the interrupt handler must be as small as possible\nIn interrupt context we can not use blocking calls\n\n\nAlso called as bottom-half since its purpose is to execute the rest of the actions from an interrupt handler top-half.\nTypical Operations\n\nInitialization\n\nEach type is described by a structure whose fields will have to be initialized.\nThe handler to be scheduled is also set at this time.\n\n\nScheduling\n\nSchedules the execution of the handler ASAP.\n\n\nMasking / Canceling\n\nDisables the execution of the handler.\nThis action can be either synchronous or asynchronous\nsynchronous action: guarantees that the handler will not run afterh the completion of canceling\n\n\n\n\n\nSoftirqs §\n "},"Linux/Linux-Commands/Linux-BIOS":{"title":"Linux BIOS","links":[],"tags":["linux"],"content":"BIOS 진입법\nsudo systemctl reboot --firmware-setup\n"},"Linux/Linux-Commands/Upgrade-Debian":{"title":"Upgrade Debian","links":[],"tags":["linux"],"content":"Installation §\nsudo apt update\nsudo apt upgrade -y\nsudo reboot\nsudo sed -i &#039;s/bullseye/bookworm/g&#039; /etc/apt/sources.list\nsudo apt upgrade --without-new-pkgs\nsudo apt full-upgrade\nTroubleshooting §\nLinux kernel build error: return code 11 dkms error §\nsudo dpkg --purge &lt;*-dkms&gt; &amp;&amp; sudo apt -f install\n# should find what package is occurring error\n# read logs\n# my case, /var/libs/dkms/kernel-mft-dkms/4.18.0/build/make.log\n# sudo dpkg --purge kernel-mft-dkms &amp;&amp; sudo apt -f install resolved the error"},"Linux/Linux-Commands/rsync":{"title":"rsync","links":[],"tags":["linux"],"content":"rsync &lt;options&gt; &lt;source&gt; &lt;destination&gt;\n"},"Linux/index":{"title":"Linux","links":[],"tags":[],"content":""},"Projects/Cookie/0314_아이디어발표":{"title":"3/14 아이디어 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0328_발표":{"title":"3/28 5주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0411_발표":{"title":"4/11 7주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0425_발표":{"title":"4/25 9주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0509_발표":{"title":"5/9 13주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0523_발표":{"title":"5/23 15주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0613_발표":{"title":"6/13 18주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0620_최종발표":{"title":"6/20 1학기 최종발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0911_소개발표":{"title":"9/11 2학기 소개발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/0925_발표":{"title":"9/25 4주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/1023_발표":{"title":"10/23 8주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/1106_발표":{"title":"11/6 10주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/1120_발표":{"title":"11/20 12주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/1211_발표":{"title":"12/11 14주차 발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/1218_최종발표":{"title":"12/18 2학기 최종발표","links":[],"tags":["keynote"],"content":""},"Projects/Cookie/index":{"title":"Cookie","links":[],"tags":["flutter","express"],"content":"\n\nRepository is currently private due to API keys.\n\n\nconst setRepoTheme = (theme) =&gt; {\n\tconst elems = document.querySelectorAll(&#039;.repo-card&#039;)\n\tfor (const elem of elems) {\n\t\tif (theme === &#039;dark&#039;)\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;dark-theme&#039;)\n\t\telse\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;light-default&#039;)\n\t}\n\twindow.tarptaeya.reloadRepoCards()\n}\nsetRepoTheme(document.documentElement.getAttribute(&#039;saved-theme&#039;))\ndocument.querySelector(&#039;#darkmode-toggle&#039;).addEventListener(&#039;change&#039;, (e) =&gt; setRepoTheme(e.target.checked ? &#039;dark&#039; : &#039;light&#039;))\n"},"Projects/Cosmos-(ongoing)/01_Intro":{"title":"Intro","links":[],"tags":[],"content":"Steps §\nCreate Project §\ncargo new cosmos\nDisable Standard Library §\n// src/main.rs\n#![no_std]\nImplement Panic Handler §\n// src/main.rs\n \n#[panic_handler]\nfn handle_panic(_info: &amp;PanicInfo) -&gt; ! {\n\tloop{}\n}\nDisable stack unwinding §\n# Cargo.toml\n \n[profile.dev]\npanic = &quot;abort&quot;\n \n[profile.release]\npanic = &quot;abort&quot;\nUnless.. §\n   Compiling cosmo-kernel v0.1.0 (/home/parkjb/cosmo-kernel)\nerror: language item required, but not found: `eh_personality`\n  |\n  = note: this can occur when a binary crate with `#![no_std]` is compiled for a target where `eh_personality` is defined in the standard library\n  = help: you may be able to compile for a target that doesn&#039;t need `eh_personality`, specify a target with `--target` or in `.cargo/config`\n \nerror: could not compile `cosmo-kernel` (bin &quot;cosmo-kernel&quot;) due to previous error\neh_personality is for implementing stack unwinding to run the destructors of all live stack variables in case of panic.\nThis ensures all memory used is freed and allows parent thread to catch the panic and continue execution.\nDrawbacks: increases the size of the executable.. abort on panic option can be useful instead.\nAdd target §\nrustup target add aarch64-unknown-none\nPlatform Support: https://doc.rust-lang.org/nightly/rustc/platform-support.html\nDisable main entry point §\n#![no_main]\n// -- fn main()\nEntry Point: _start §\n#[no_mangle]\npub extern &quot;C&quot; fn _start() -&gt; ! {\n    loop {}\n}\nUnless.. §\n   Compiling cosmo-kernel v0.1.0 (/home/parkjb/cosmo-kernel)\nerror: requires `start` lang_item\n \nerror: could not compile `cosmo-kernel` (bin &quot;cosmo-kernel&quot;) due to 1 previous error\nUseful Tools §\nInstall §\ncargo install cargo-binutils\nrustup component add llvm-tools\nrust-nm: List Symbols §\nrust-nm target/aarch64-unknown-none/debug/kernel\n0000000000210120 T _start\n\nrust-objdump: Inspect ELF File §\n\nELF: Executable &amp; Linkable File\n\nFile Headers: -f §\nrust-objdump -f target/aarch64-unknown-none/debug/kernel\ntarget/aarch64-unknown-none/debug/kernel:\tfile format elf64-littleaarch64\narchitecture: aarch64\nstart address: 0x0000000000210120\n\nSections: -h §\nrust-objdump -h target/aarch64-unknown-none/debug/kernel\ntarget/aarch64-unknown-none/debug/kernel:\tfile format elf64-littleaarch64\n\nSections:\nIdx Name           Size     VMA              Type\n  0                00000000 0000000000000000\n  1 .text          00000008 0000000000210120 TEXT\n  2 .debug_abbrev  00000133 0000000000000000 DEBUG\n  3 .debug_info    000005f3 0000000000000000 DEBUG\n  4 .debug_aranges 00000040 0000000000000000 DEBUG\n  5 .debug_ranges  00000030 0000000000000000 DEBUG\n  6 .debug_str     00000499 0000000000000000 DEBUG\n  7 .comment       00000040 0000000000000000\n  8 .debug_frame   00000050 0000000000000000 DEBUG\n  9 .debug_line    00000058 0000000000000000 DEBUG\n 10 .symtab        00000120 0000000000000000\n 11 .shstrtab      00000085 0000000000000000\n 12 .strtab        00000047 0000000000000000\n\nDisassembling: -d §\nrust-objdump -d target/aarch64-unknown-none/debug/kernel\ntarget/aarch64-unknown-none/debug/kernel:\tfile format elf64-littleaarch64\n\nDisassembly of section .text:\n\n0000000000210120 &lt;_start&gt;:\n  210120: 14000001     \tb\t0x210124 &lt;_start+0x4&gt;\n  210124: 14000000     \tb\t0x210124 &lt;_start+0x4&gt;\n\nrust-strip §\nrust-strip target/aarch64-unknown-none/debug/kernel\n\nremoves debug information\n"},"Projects/Cosmos-(ongoing)/02_Booting-(UEFI)":{"title":"Booting (UEFI)","links":[],"tags":[],"content":"The Boot Process §\n\nExecutes Motherboard ROM firmware code\n\npower-on-self-test(https://en.wikipedia.org/wiki/Power-on_self-test)\ndetect available RAM\npre-initialize CPU &amp; other hardwares\nlooks for bootable disk\n\n\n\nQEMU §\nQEMU-ARM64 UEFI HOWTO: https://cdn.kernel.org/pub/linux/kernel/people/will/docs/qemu/qemu-arm64-howto.html\nPatch for bootloader_api crate §\ndiff --git a/api/src/lib.rs b/api/src/lib.rs\nindex 4ada525..83a54ed 100644\n--- a/api/src/lib.rs\n+++ b/api/src/lib.rs\n@@ -137,5 +137,9 @@ macro_rules! entry_point {\n #[doc(hidden)]\n pub fn __force_use(slice: &amp;[u8]) {\n     let force_use = slice.as_ptr() as usize;\n-    unsafe { core::arch::asm!(&quot;add {0}, 0&quot;, in(reg) force_use, options(nomem, nostack)) };\n+    // for aarch64\n+    unsafe { core::arch::asm!(&quot;add {0}, {0}, 0&quot;, in(reg) force_use, options(nomem, nostack)) };\n+\n+    // for x86_64\n+    // unsafe { core::arch::asm!(&quot;add {0}, 0&quot;, in(reg) force_use, options(nomem, nostack)) };\n }\n\n\n\nTranslate instruction from x86 to aarch64\n\nReference §\nhttps://developer.arm.com/documentation/dui0068/b/ARM-Instruction-Reference/ARM-general-data-processing-instructions/ADD—SUB—RSB—ADC—SBC—and-RSC\nhttps://c9x.me/x86/html/file_module_x86_id_5.html\nBootable Disk Image §\nmkdir kernel\nmv src kernel/\nmv Cargo.toml kernel/\ncargo init --new cosmos\n# top-level Cargo.toml\n[workspace]\nmembers = [&quot;kernel&quot;]\nBootloader §\nrustup install nightly\n# rust-toolchain.toml\n[toolchain]\nchannel = &quot;nightly&quot;\nrustup target add aarch64-unknown-uefi\ncargo build --target aarch64-unknown-uefi"},"Projects/Cosmos-(ongoing)/ARM/Interrupt":{"title":"Interrupt","links":[],"tags":[],"content":"https://www.geeksforgeeks.org/arm-interrupt-structure/"},"Projects/Cosmos-(ongoing)/ARM/Processor-Modes":{"title":"Processor Modes","links":[],"tags":[],"content":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModeDescriptionCPSR M[4:0]UserUser Task나 Application을 수항 할때의 동작모드로 모든 동작모드 중 유일하게 비특권 모드이다. User Mode는 메모리, I/O장치와 같은 시스템 자원을 사용하는데 제한을 두어 사용자의 실수를 방지한다. 다른 모드(SVC)로 이동하기 위한 방법으로는 소프트웨어 인터럽트를 발생시킨다.10000bFIQ(Fast IRQ)2개의 인터럽트 소스 중 아주 빠르게 인터럽트를 처리할 수 있도록 구성된 모드이다. 빠른 처리를 위해서 Exception Vector에서도 최하단에 존재하고 별도의 레지스터를 소유한다.10001bIRQ(Interrupt Request)일반적으로 사용되는 인터럽트로 외부 장치에서 요청되는 하드웨어적인 IRQ의 발생에 의해 ARM Core는 IRQ모드로 전환하고 인터럽트를 처리한다.10010bSVC(Superviser)대부분의 시스템 자원을 자유롭게 관리할 수 있는 동작모드로 주로 커널이나 디바이스 드라이버를 처리할 때(System Call) 동작되는 모드이다.Reset 신호 입력 시 및 SWI가 발생하면 SVC Mode로 전환된다.10011bAbort메모리에서 명령을 읽거나 데이터를 읽거나 쓸때 오류가 발생할 때 Abort Mode로 전환하여 오류를 처리한다. 커널등의 패닉시 Abort Mode로 전환되어 스택 내용이 전달됨을 알 수 있다.10111bUndefined명령어를 읽어 실행하고자 하나 읽어온 명령이 디코더에 정의되어 있지 않은 명령인 경우 발생되는 오류를 처리하는 모드이다.11011bSystemUser Mode와 동일한 Register를 사용하고 동일한 용도로 사용된다. User Mode와의 차이점은 특권을 갖고 있다는 것이다. (ex : OS Kernel)11111b\nhttps://julrams.tistory.com/12"},"Projects/Doge_Driver":{"title":"Doge Driver","links":[],"tags":[],"content":"\n\n\n\n\nconst setRepoTheme = (theme) =&gt; {\n\tconst elems = document.querySelectorAll(&#039;.repo-card&#039;)\n\tfor (const elem of elems) {\n\t\tif (theme === &#039;dark&#039;)\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;dark-theme&#039;)\n\t\telse\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;light-default&#039;)\n\t}\n\twindow.tarptaeya.reloadRepoCards()\n}\nsetRepoTheme(document.documentElement.getAttribute(&#039;saved-theme&#039;))\ndocument.querySelector(&#039;#darkmode-toggle&#039;).addEventListener(&#039;change&#039;, (e) =&gt; setRepoTheme(e.target.checked ? &#039;dark&#039; : &#039;light&#039;))\n"},"Projects/Elevator-Controller":{"title":"엘레베이터 컨트롤러","links":[],"tags":["Verilog","DigitalSystem","assignment"],"content":"\nSpecifications §\n\nThe elevator control system consists of an elevator car and a controller.\n\nYou should design 3 Verilog modules including a test bench.\nAll signal names in the codes should follow the below diagram.\n\n\nThe elevator operates in a 5th floor building.\n\nExample specification\n\nThe elevator is currently on the 2nd floor.\nA user on the 4th floor pushes the down button.\nThe elevator moves up to the 4th floor, and then the door opens.\nThe user in the elevator pushes the 1st floor button.\nThe door closes, and then move down to 1st floor, and finally opens.\n\n\nMaximally 2 persons use the elevator control system.\n\nFor example, during the above procedure 3, if another user on the 5th floor pushes the down button, then the elevator moves up to 5th floor, and then 4th floor.\n\n\nIt takes one second for the elevator to move one floor.\nIt takes one second for the door to open and close, respectively.\n\nAbstract §\n이번 과제에서는 최대 2인의 사용자 입력에 대해서 엘레베이터가 방문해야 할 층을 스케줄링하고, 엘레베이터가 이동하는 로직을 구현해야 한다. 과제에서 주어진 모듈간의 큰 틀은 다음과 같았다.\n\n이를 세부적으로 구현하기 위하여 이와 같은 구조로 실제 모듈들을 설계하였다.\n\nTarget_Controller는 엘레베이터를 목표한 층으로 이동시켜주는 Controller의 sub-module이다. 또, 동일한 Input으로 사용자의 입력을 저장하기 위해서 set_clk를 이용하여 posedge가 나타날 때에만 레지스터에 값을 저장하도록 제작하였다. 각각의 층수들은 3비트 unsigned binary로 나타내었다.\nController 모듈 §\nController 모듈 State 정의 §\n개발의 편의를 위하여 하나의 state에 대해 두가지 변수를 이용하였으며, 각각 done과 on_board이다. Done은 해당 비트의 사용자가 도착하였는지에 대한 정보이며, on_board는 해당 비트의 사용자가 현재 엘레베이터를 탑승하였는지에 대한 정보이다. 즉 예를 들어, done=00, on_board=11의 경우 2명의 사용자 모두 아직 목적지에 도착하지 못하였으며, 2명의 사용자 모두 엘레베이터를 탑승하고 있는 상황에 대한 state이다. 또 다른 예로 done=01, on_board=00의 경우 #2 사용자가 아직 목적지에 도착하지 못하였으며, 엘레베이터에 탑승하지도 못한 state임을 나타낸다. 이러한 notation을 토대로 state를 구상하면 다음과 같은 state들이 나올 수 있다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoneOn_board설명1100사용자 입력이 없는 경우의 state10001번 사용자가 아직 탑승하지 않았고 엘레베이터를 기다리고 있는 state + 한명의 사용자 입력을 추가적으로 받을 수 있는 상태10011번 사용자가 엘레베이터에 탑승하여 도착층으로 이동하는 state+ 한명의 사용자 입력을 추가적으로 받을 수 있는 상태01002번 사용자가 아직 탑승하지 않았고 엘레베이터를 기다리고 있는 state+ 한명의 사용자 입력을 추가적으로 받을 수 있는 상태01102번 사용자가 엘레베이터에 탑승하여 도착층으로 이동하는 state+ 한명의 사용자 입력을 추가적으로 받을 수 있는 상태00001번 사용자와 2번 사용자가 둘 다 입력을 하였고, 둘 다 엘레베이터를 탑승하지 못하고 대기중인 state00011번 사용자와 2번 사용자가 둘 다 입력을 하였고, 1번 사용자는 엘레베이터에 탑승하여 자신의 도착층으로 이동중이고, 2번 사용자는 아직 엘레베이터에 탑승하지 않고 기다리고 있는 state00101번 사용자와 2번 사용자가 둘 다 입력을 하였고, 2번 사용자는 엘레베이터에 탑승하여 자신의 도착층으로 이동중이고, 1번 사용자는 아직 엘레베이터에 탑승하지 않고 기다리고 있는 state00111번 사용자와 2번 사용자가 둘 다 입력을 하였고, 둘 다 엘레베이터에 탑승하여 자신의 도착층으로 이동중인 state1101탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.1110탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.1111탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.1010탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.1011탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.0101탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.0111탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다.\n이를 토대로 State Diagram을 그려보면 다음과 같이 나타낼 수 있다.\n\n위의 2개의 bit가 done, 아래 2개의 bit가 on_board를 나타내며, transition하는 각각의 조건에 대해서는 색깔로 구분하였다. 또, 간단하게 표현하기 위해서 사용자가 입력하였을 때 state이 transition하는 것에 대해서는 표기하지 않았으며, 그 외 다른 조건들에 대해서는 자기 자신의 state을 유지하도록 하였다. 해당 state transition 만을 코드로 간략하게 표기하면 다음과 같다.\n\nController 모듈은 다음과 같이 크게 3가지 부분으로 구성된다.\n입력단 §\n입력단의 경우 최대 2명의 사용자가 동시에 이용할 수 있으므로, 출발층, 도착층, 방향 세가지 입력을 받아 이를 저장해두는 역할을 한다. State를 입력받아 저장하기 위해서 set_clk라는 클락을 정의하였으며, 해당 input에서 posedge가 있을 때에 대해서만 유효한 input으로 간주한다. Posedge 입력이 들어올 때마다 input을 받아 저장하는데, 이때 출발층과 도착층이 같거나, 올라가는 입력인데 출발층보다 도착층이 작거나 거꾸로 내려가는 입력인데 출발층이 도착층보다 클 경우에 대해서는 시뮬레이터에 경고 메시지를 발생시키고 해당 input을 무시하였다.\n올바른 입력이 들어왔을 때 done state를 확인하여 만약 00일 경우, 즉 2명의 사용자 모두 아직 도착하지 못했을 경우에 대해서는 엘레베이터가 아직 모든 일을 처리하지 못하였기 때문에 경고 메세지를 발생시키고 해당 Input을 무시하였다. 만약 done state의 두 비트중 어떤 하나라도 1일 경우 해당하는 레지스터에 사용자의 Input을 저장해 두었으며, done 의 두 비트중 1이였던 비트를 0으로 바꾸어 해당 동작을 수행해야 하는 상태로 state transition을 수행하였다.\n타겟층 선택단 (output logic) §\n최대 2명의 사용자에 대해서 출발층과 도착층을 비교하여 현재 이동해야 할 타겟층을 선택하는 역할을 한다. 즉 현재 상태에 대해서 이동해야 할 타겟 층수를 결정하는 단계이다. 이를 결정하는 방법은 다음의 표와 같다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDoneOn_board출력110010001번 사용자의 출발층10011번 사용자의 도착층01002번 사용자의 출발층01102번 사용자의 도착층0000상황에 따라 판단 1번, 2번 사용자 모두 위로 갈 경우: 1번 사용자의 출발층과 2번 사용자의 출발층 중 더 작은 층수1번, 2번 사용자 모두 아래로 갈 경우: 1 번 사용자의 출발층과 2번 사용자의 출발층 중 더 큰 층수1번, 2번 사용자가 서로 다른 방향으로 갈 경우: 1 번 사용자의 출발층(이 경우 임의의 사용자 한명에 대해 먼저 처리하면 다른 State로 transition 되므로 1번층을 우선적으로 선택하였다. )0001상황에 따라 판단1번, 2번 사용자 모두 위로 갈 경우: 현재 1번 사용자만 탑승해 있으므로, 1번 사용자의 도착층과 2번 사용자의 출발층을 비교하여 1번 사용자의 도착층에 가는 중에 2번 사용자의 출발층을 거쳐가면, 2번 사용자의 출발층에 가야하고, 그렇지 않을 경우 1번 사용자의 도착층에 가야한다. 따라서 1** 번 사용자의 도착층과 **** 2 번 사용자의 출발층 중 더 작은 층수1번, 2번 사용자 모두 아래로 갈 경우: 마찬가지로, 이 경우에는 1 번 사용자의 도착층과 **** 2 번 사용자의 출발층 중 더 큰 층수 를먼저 방문해야 한다.1번, 2번 사용자가 서로 다른 방향으로 갈 경우: 현재 1번 사용자가 탑승해 있으므로, 먼저 1번 사용자를 도착층으로 데려가야 한다. 따라서 1 번 사용자의 도착층**0010상황에 따라 판단 (Done 00, On_board 01의 상황과 유사) 1번, 2번 사용자 모두 위로 갈 경우: 현재 2번 사용자만 탑승해 있으므로, 2번 사용자의 도착층과 1번 사용자의 출발층을 비교하여 2번 사용자의 도착층에 가는 사이에 1번 사용자의 출발층을 거쳐간다면 1번 사용자의 출발층을 목적지로 삼아야 하고, 그렇지 않을 경우 2번 사용자의 도착층에 도착해야 한다. 따라서, 1** 번 사용자의 출발층과 **** 2 번 사용자의 도착층 중 더 작은 층수1번, 2번 사용자 모두 아래로 갈 경우: 마찬가지로, 이 경우에는 1 번 사용자의 출발층과 **** 2 번 사용자의 도착층 중 더 높은 층수 를 먼저 방문해야 한다.1번, 2번 사용자가 서로 다른 방향으로 갈 경우: 현재 2번 사용자가 탑승해 있으므로, 먼저 2번 사용자를 도착층으로 데려가야 한다. 따라서 2 번 사용자의 도착층**0011상황에 따라 판단1번, 2번 사용자 모두 위로 갈 경우: 1** 번 사용자의 도착층과 **** 2 **번 사용자의 도착층 중 더 작은 층수1번, 2번 사용자 모두 아래로 갈 경우: 1 번 사용자의 도착층과 2번 사용자의 도착층 중 더 큰 층수1번, 2번 사용자가 서로 다른 방향으로 갈 경우: 서로 다른 방향으로 가는데 동시에 타고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다. 1101탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.1110탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.1111탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.1010탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.1011탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.0101탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.0111탑승한 사용자가 모두 도착층에 도착하였는데 엘레베이터에 탑승하고 있을 경우는 존재할 수 없다. 따라서 이전의 출력을 유지한다.\n\n이를 작성한 코드는 위와 같다.\n타겟층 이동단 §\n타겟층이 선택되었을 때, 엘레베이터의 현재 층수와 비교하여 해당 타겟층으로 이동하는 역할을 한다. 해당 부분은 target_controller 모듈로 따로 선언하였다. 해당 모듈은 타겟층과 현재 엘레베이터의 상태를 비교해서 엘리베이터에 올라가는 명령을 내릴지, 내려가는 명령을 내릴지, 문을 열지 닫을지에 대한 정보를 Elevator 모듈에 전달하는 중간 모듈이다. 엘레베이터가 각 동작을 수행할 때에 1초씩 걸림을 고려하여 지연을 주었다.\nElevator 모듈 §\nElevator 모듈의 경우 총 10가지 State로 나눈 State Machine을 구상하여 제작하였다. 회로의 안정성을 위해서 그레이 코드를 이용하여 상태들을 나타내었으며, 각각의 상태들에 대한 상태머신은 다음과 같다.\n\n상태에 대한 Notation은 1Fc는 floor1_closed, 2Fc는 floor2_closed, 3Fo는 floor3_closed 등등과 같으며, 3가지 input (혹은 DU를 하나의 버스로 생각한다면 2가지 input, 실제 코드에서는 이와 같이 구현되어 있다.) 은 각각 O, D, U로, 각각 Open, Down, Up을 의미한다. 즉, D’U의 경우 내려가는 것에 대한 입력, DU’의 경우 올라가는 것에 대한 입력, DU 혹은 D’U’은 IDLE상태로 있는 것에 대한 입력이며, 올라가거나 내려갈때는 항상 문이 닫힌 상태로, IDLE 상태일때는 문이 열리고 닫힌 상태 모두 가능하다.\n각각의 층에서 문이 닫혀있는 상태일 때, 올라가는 입력 (O’D’U)이 들어오면 위층의 닫힌 상태로 상태를 바꾸었으며, 반대로 내려가는 입력 (O’DU’)이 입력된다면 아랫층의 닫힌 상태로 상태를 바꾸었다. 또, 문이 열리는 입력 (O)이 입력된다면 해당 층에서 문이 열린 상태로 상태를 바꾸었으며, 문이 열린 상태에서 문을 닫는 입력 (O’)을 입력하였을 때에는 해당 층의 문이 닫힌 상태로 상태를 바꾸도록 하였다. 1층에서 닫힌 상태로 있을 경우, 만약 O’DU’ (내려가는 입력)과 같이 불가능한 입력이 들어온다면 해당 입력을 수행하지 않고 같은 상태로 유지하도록 하였으며, 이는 5층에서 O’D’U (올라가는 입력)에서도 마찬가지로 적용하였다.\n위의 상태머신에서 그레이 코드화 시켜 예기치 못한 오류를 최소화하도록 각각의 상태들을 할당하였다. 즉, 각각의 상태에 대한 코드는 다음과 같다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloor1_closed0001floor1_open1001floor2_closed0011floor2_open1011floor3_closed0010floor3_open1010floor4_closed0110floor4_open1110floor5_closed0111floor5_open1111\n즉, MSB는 문이 열려있는지 닫혀있는지에 대한 상태이며, 나머지 3비트는 각각의 층에 대한 그레이 코드이다. 위의 상태머신 다이어그램을 참조하면 두가지 이상의 비트가 동시에 바뀌는 경우는 없음을 확인할 수 있다.\n최종적으로는, 각 상태를 문이 열렸는지 혹은 몇층인지로 변환해주는 부분이 필요하여, 그레이 코드를 부호가 없는 binary로 xor 연산을 이용하여 변환해 주었으며, 문의 열림/닫힘 상태는 MSB 비트를 출력하여 각각의 상태에 대해서 변환한 값을 출력해주었다.\n실제 코드상에서 이를 구현할 때에는 문이 열리고 닫힐 때 1초, 엘레베이터가 층을 이동할 때 1초의 delay가 있으므로 클락을 이용하여 다른 상태로 전환될 때 delay를 주어 이를 가상으로 구현하였다.\n테스트벤치 §\n엘레베이터는 초기상태로 1층에서 문을 닫은 상태로 정지하고 있다고 가정하였다. 이는 엘레베이터 모듈에 정의되어 있다.\n예제 1 §\n해당 테스트벤치는 다음과 같은 입력을 가진다.\n\n초기상태 5초딜레이\n4층→2층 5초 딜레이\n5층→3층 14초 딜레이 (엘레베이터가 이전 작업들을 마저 수행하기 위해서 기다리는 delay로, 이전 수행중인 작업을 완료하기 위해서는 최소 11초의 딜레이가 필요하다. )\n4층→3층\n끝날때까지 충분히 딜레이\n\n\n의도하였던 대로, 1층에 있는 엘레베이터가 4층의 사용자를 데려가기 위해 4층으로 이동중에 5층에서 내려가는 입력이 들어와 5층을 우선적으로 방문하여 두명의 사용자를 같이 내려갈 수 있도록 target_floor_input이 바뀌었고, 이에 따라 엘레베이터도 5층을 우선적으로 방문하여 문을 열어 2번 사용자를 태운다. 그리고 순차적으로 4층에 방문하여 1번 사용자도 태운 뒤, 2번 사용자와 1번 사용자 각자의 목적지인 3층과 2층을 순차적으로 방문하여 사용자가 하차할 수 있음을 확인하였다. 또, 1번 사용자의 목적지에 도달한 이후에도 새로운 사용자의 input을 수행하기 위해서 4층으로 target_floor_input이 세팅되어 엘레베이터가 이동하였음을 확인하였다. 그리고 마지막 사용자까지 최종 도착층인 2층에 내려주고 idle 상태로 기다림을 확인할 수 있다.\n예제 2 §\n해당 테스트벤치는 다음과 같은 입력을 가진다.\n\n2층→5층 5초 딜레이\n3층→4층 5초 딜레이\n5초 딜레이 (엘레베이터가 이전 작업들을 마저 수행하기 위해서 기다리는 delay로, 이전 수행중인 작업을 완료하기 위해서는 최소 4초의 딜레이가 필요하다. )\n4층→3층\n끝날때까지 충분히 딜레이\n\n\n의도하였던 대로, 1층에서 4층에 있는 첫번째 사용자를 태우기 위해 올라가던 중에 5층에 있는 두번째 사용자가 입력하였기 때문에, 효율을 위해서 5층을 먼저 방문하여 두번째 사용자를 태운 뒤, 4층을 방문하여 첫번째 사용자를 태우고, 목표한 3층과 2층으로 순차적으로 방문한다.\n\n\n\n\nconst setRepoTheme = (theme) =&gt; {\n\tconst elems = document.querySelectorAll(&#039;.repo-card&#039;)\n\tfor (const elem of elems) {\n\t\tif (theme === &#039;dark&#039;)\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;dark-theme&#039;)\n\t\telse\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;light-default&#039;)\n\t}\n\twindow.tarptaeya.reloadRepoCards()\n}\nsetRepoTheme(document.documentElement.getAttribute(&#039;saved-theme&#039;))\ndocument.querySelector(&#039;#darkmode-toggle&#039;).addEventListener(&#039;change&#039;, (e) =&gt; setRepoTheme(e.target.checked ? &#039;dark&#039; : &#039;light&#039;))\n"},"Projects/OS-Assignments/index":{"title":"OS Assignments","links":[],"tags":["os","assignment","C"],"content":""},"Projects/OS-Assignments/pa0":{"title":"PA0: Warming up C programming","links":[],"tags":["os","assignment","C"],"content":"Simple Linux List Manipulation &amp; C Warming Up Project\nhttps://github.com/parkjbdev/SCE213_OS/tree/os-pa0"},"Projects/OS-Assignments/pa1":{"title":"PA1: My Amazing Shell","links":[],"tags":["os","assignment","C"],"content":"https://github.com/parkjbdev/SCE213_OS/tree/os-pa1\nLogic §\nmash.c §\nflowchart LR\n  initialize --&gt; while --&gt; get_command --command--&gt; parse_command -- nr_tokens, tokens --&gt; run_command --&gt; free_command_tokens --&gt; if_terminate\n  if_terminate{{run_command != 0}} --true--&gt; while\n  if_terminate --false--&gt; finalize\n\nmash.c에서는 command를 실행하기 전에 command를 입력받고, 이를 parser.c에 정의된 parse_command 함수를 통해 공백을 기준으로 command를 토큰화하여 run_command에 전달하여 command를 실행한 뒤, 메모리에서 token들을 해제하는 과정을 거친다. 위 flowchart에 그 과정과 인자들의 전달을 모식화해두었다.\npa1.c §\nflowchart TD\nSTART --&gt; strcmp{{&quot;tokens[0]&quot;}}\nstrcmp --exit--&gt; exit[return 0]\nstrcmp --cd--&gt; cd[builtin_cd]\nstrcmp --alias--&gt; alias[builtin_alias]\nstrcmp --else--&gt; replace_alias --&gt; execute\n\npa1.c 에서는 우선 첫번째 입력된 토큰 tokens[0]가 builtin function인지 판단하여, builtin function일 경우 nr_tokens에 따라 올바른 동작을 수행할 수 있도록 하였다. builtin function이 아닐 경우, 즉, 명령어를 실행해야 될 경우에는 우선 alias로 등록된 token이 있는지 확인하여 이를 대체하는 과정을 거친 후 execute함수를 통해 실행하게 된다. 위는 간단한 flowchart이다. 각각의 함수의 동작과정에 대해서는 아래에 기술하였다.\nFeatures §\nBuiltin Command - cd §\ncd 기능은 현재의 working directory를 바꾸는 명령어로, builtin_cd 함수로 실행되는데, 인자로 변경할 디렉토리의 주소 dir이 입력되면, 이에 맞는 곳으로 이동한다.\n전달된 인자가 ~일 경우 getenv 를 이용하여 환경변수 목록중에서 $HOME 환경변수를 찾아 home directory 로 이동할 수 있도록 하였다. 또, cd만 입력되었을 때 역시 home directory로 이동해야 하는데, 이는 run_command 함수에서 전달된 인자가 1개일 때에는 builtin_cd(&quot;~&quot;)가 실행되도록 하여 의도한 동작을 수행할 수 있도록 하였다.\ncd 명령어가 성공적으로 실행되었을 때에 builtin_cd 함수는 1을 반환하고, 그렇지 않을 경우 perror를 통한 에러메세지와 함께 -1을 반환하도록 하였다.\n추가구현 - 이전 directory 이동: - §\n추가적으로 전달된 인자가 -일 경우 이전 디렉토리를 저장해두는 기능을 구현하였다. 이를 위해 디렉토리를 이동할 때마다, 환경변수에 등록된 $PWD값과 $OLDPWD값을 setenv를 통해 다시 설정하여 주었다.\nLessons Learned §\ncd 기능을 구현하며 환경변수를 읽고 쓰는 getenv, setenv 함수, current working directory를 읽고 변경하는 getcwd, chdir 함수를 알게되었다.\nBuiltin Command - alias §\nalias 기능은 기존에 run_command로 입력된 tokens 중에 alias로 등록되어 있는 token들을 매치되는 token들로 대체하는 방식으로 기능을 구현하였다.\n이를 구현하기 위해서 하나의 alias에 대한 정보를 담는 구조체 Alias 를 정의하였으며, 해당 구조체의 member로, 대체될 문자열 alias, 해당 alias에 대해 대체시켜야 할 토큰들의 배열 tokens, tokens 배열의 길이를 저장하는 nr_tokens를 정의하였다. 새로운 alias를 동적할당하거나 메모리에서 해제할 때, 편의를 위해 new_alias, delete_alias 함수를 정의하여 이용하였다.\n또, 여러 alias 정보들을 저장하는 Alias의 배열 Alias **aliases 과 총 alias들의 개수 alias_cnt를 정의하였다.\n이를 간단한 다이어그램으로 나타내면 다음과 같다.\nclassDiagram\n  class Alias {\n    char* alias\n    int nr_tokens\n    char **tokens\n    new_alias()\n    delete_alias()\n    print_alias()\n  }\n\n  class Aliases {\n    int alias_cnt\n    Alias **aliases\n    builtin_alias_add()\n    builtin_alias_print()\n  }\n\n\n새로운 alias 추가과정 - builtin_alias_add §\n새로운 alias를 추가하는 일련의 과정은 다음과 같다.\nflowchart LR\n  builtin_alias_add --&gt; found\n  found{find_alias}\n  found -- not found --&gt; increase_alias_cnt[alias_cnt++] --&gt; realloc_aliases[realloc aliases] --&gt; add_alias[add new alias]\n  found -- found --&gt; replace_alias[replace tokens and nr_tokens]\n\n즉, alias를 추가하기 전에, find_alias 함수를 통해 aliases 배열에 기존에 등록된 같은 이름의 alias가 존재하는지 확인한 후, 같은 alias가 존재할 경우 이를 새로운 tokens와 nr_tokens로 대체하고, 기존에 같은 alias가 존재하지 않을 경우 새로운 alias를 추가하기 위해 aliases 배열을 alias_cnt+1 만큼 재할당해주어 새로운 alias를 등록해주는 과정을 거친다.\nalias 출력 - builtin_alias_print §\nbuiltin_alias_print 함수는 초기에는 모든 alias들을 출력하는 함수로 만들었으나, 개별 alias에 대해서 출력할 수 있도록 개선하였다.\n이를 위해 run_command에서 alias만 입력되어 token이 1개 입력된 경우, alias와 함깨 token이 2개 입력된 경우, 즉 alias ll과 같은 경우를 나누어 builtin_alias_add에 인자로 전달하였다.\n해당 함수에 NULL값이 들어올 경우, 모든 alias들을 출력하도록 하였고, 문자열이 들어올 경우 해당하는 alias를 find_alias를 통해 찾아서 출력하도록 하였다.\nalias replacement §\nbuiltin commands가 아닌 경우, execute을 통하여 command를 실행하기 전에, tokens를 순회하며 alias로 대체할 token이 있는지 확인하는 과정을 거친다. alias로 대체할 token이 존재한다면, 이를 대체하기 위해서 tokens[] 배열의 뒷부분을 alias의 token 개수만큼 미루는 작업을 진행한다.\n그리고 alias가 있던 index부터 미뤄진 만큼의 index에 alias token들을 넣는과정을 진행한다.\n최종적으로, aliasing 된 token들의 aliasing을 방지하기 위해 for loop을 순회하는 iterator i를 밀어낸 인덱스만큼 증가시켜 주었다. (ex. alias hello hi hello; echo hello world 의 실행결과는 hi hello world 여야 함, re-aliasing을 할 경우 무한히 긴 문자열이 생성됨)\n메모리 해제 §\n최종적으로 쉘을 terminate하기 전에 동적할당한 aliases의 개별 element와 aliases을 finalize 함수에서 해제해주었다.\nLessons Learned §\nalias 기능을 구현하며 메모리를 동적으로 할당하고 해제하는 과정을 통해 포인터와 이를 활용한 동적길이를 가진 배열에 대한 이해도를 향상시킬 수 있었다.\n특히, 문자열을 복사할 때, 기존에는 malloc을 통해 문자열을 저장하는 공간을 동적으로 만들고, 여기에 strcpy를 통해 복사하고는 하였는데, 이를 한번에 해주는 strdup이라는 유용한 함수를 알게되었다.\nExecution &amp; Pipe Implementation - execute §\n새로운 프로세스의 실행과 pipelining 부분의 logic에서 겹치는 부분이 발생하여 같은 section으로 포함한다.\n우선 execute을 실행하기 전에, tokens와 nr_tokens를 입력받아 이를 파이프라인 기호 | 단위로 나누어 command 단위로 토큰들을 분리시켰다.\n해당 과정은 parse_commands에서 수행된다. 명령어 단위로 분리된 토큰들을 저장하는 구조체 Command 를 정의하였으며, 여러 명령어들에 대한 list 와 명령어의 갯수 nr_commands 가 정의된 구조체 Commands 를 정의하였다. parse_commands  의 결과로 commands를 받아, commands-&gt;list[i]-&gt;tokens 단위별로 exec_command 에서 execvp 를 통해 실행하게 된다.\nExecution §\nPipelining이 없는 execution의 경우 이전에 pipeline을 구현하지 않은 상태인 50783ff4 커밋의 170라인 또는, 최종 커밋의 execution 함수의 마지막 fork이후 과정에서 이중으로 감싸진 if 문을 제외하고 코드를 참조하면 된다.\n즉, 프로그램이 실행되는 전체적인 과정은 fork를 진행하여 프로세스를 복사한 뒤, child process에서는 execvp함수를 호출하여 프로세스를 실행시키고, exit하는 과정을 거치고, parent process에서는 child process가 exit되는 것을 wait 함수를 통해 대기한다.\n그 과정을 flowchart로 표현하면 아래와 같다.\nflowchart LR\n  START --&gt;\n  last_fork{{pid=fork}}\n  last_fork --pid&lt;0--&gt; fork_error[fork_failed]\n  last_fork --pid==0--&gt; child[Child]\n  child --&gt; execute --&gt; exit\n  last_fork --pid&gt;0--&gt; par[Parent] --&gt; wait\n  wait-.-exit\n  wait --&gt; RETURN\n\nPipeLining §\nflowchart TD\nSTART --&gt;\nparse_commands --&gt; pipe --&gt; is_last_command{{no pipeline?}} --false--&gt;for_commands\nis_last_command--true--&gt;last_command\n\nfor_fork_par_close_write --&gt; last_command --&gt; last_fork{{pid=fork}}\nlast_fork --pid&lt;0--&gt; fork_error[fork_failed]\nlast_fork --pid==0--&gt; child[Child]\nchild --&gt; were_pipelines{{pipeline exists?}}\nwere_pipelines --false--&gt;execute--&gt;exit\nwere_pipelines --true--&gt;child_dup_read\nchild_dup_read[&quot;dup2 pipe_fd[0] as STDIN&quot;] --&gt; close_read[close read end of pipe] --&gt; execute\nlast_fork --pid&gt;0--&gt; par[Parent] --&gt; wait\nwait-.-exit\nwait --&gt; RETURN\n\n\nsubgraph for commands except last one\n  direction TB\n  for_commands[for commands except last one]--&gt;for_fork{{pid=fork}}\n  for_fork --pid&lt;0 --&gt; for_fork_error[fork failed]\n  for_fork --pid==0--&gt; for_fork_child[Child] --&gt; is_first_command\n  for_fork --pid&gt;0--&gt; for_fork_par[Parent] --&gt; for_fork_par_wait[wait] --&gt; for_fork_par_close_write[close write end of pipe] --&gt; for_commands\n  for_exit -.- for_fork_par_wait\n\n  subgraph child_process\n    direction TB\n    is_first_command{{is it first command?}} --true--&gt; for_child_dup_read[&quot;dup2 pipe_fd[0] as STDIN&quot;]\n    --&gt;for_child_dup_write\n    is_first_command --false--&gt;for_child_dup_write[&quot;dup2 pipe_fd[1] as STDOUT&quot;]--&gt;close_child_read[close read end of the pipe]--&gt;for_execute[execute] --&gt; for_exit[exit]\n    end\n  end\n\n\nTestCase에는 파이프라이닝이 하나인 케이스만 존재하는것 같았으나, Multi Pipeline을 지원하기 위해 command 단위별로 for loop을 순회하며 프로세스를 실행시켰다. 그 과정을 flowchart로 그려보았으나, 과정에 비해 더 복잡하게 보이므로, 첨부하지는 않았다. (gitlab REPORT.md 참조)\n전체적인 흐름은 앞에서 언급한 Execution 과정과 동일하나, pipe 함수를 통해 pipe를 생성하고 dup2를 통해 pipe의 read end를 stdin으로 혹은 pipe의 write end를 stdout으로 지정하는 과정, pipe를 여닫는 과정 등이 추가된다. 일반적인 대부분의 프로세스들은 입력과 출력을 stdin에서 받거나 stdout으로 출력하기 때문에, pipe를 이용하여 입력과 출력을 다른 프로세스에 전달하는 데에 dup2 함수가 사용된다.\n자식 프로세스에서는 먼저, pipe를 생성한 뒤, |을 통해 구분된 명령어 단위로 프로세스를 실행한다.\n그리고, child process에서, dup2 를 이용하여 stdin으로 들어왔을 입력 대신 pipe의 read_end인 pipe_fd[0]에서 입력을 받아오고, stdout에 출력될 출력을 pipe의 write_end인 pipe_fd[1]에 입력되도록 한다. 단, 첫번째로 실행하는 프로세스일 경우에는 stdin에서 받아올 입력이 없기 때문에 stdin 대신 pipe_fd[0]에서 입력을 받아오는 동작은 생략한다.\n입력을 받아온 뒤에는 출력을 pipe의 write_end에 작성하기 위해서 read_end를 닫아준다.\n부모 프로세스에서는 자식 프로세스가 실행된 뒤, pipe의 write_end인 pipe_fd[1]을 닫아주어 pipe에 EOF임을 전달하도록 하였다.\n즉, 전체적으로 보았을 때, 파이프라인을 통하여 n개의 command가 입력되었을 때, 각 command를 실행하기 위해 n번의 fork가 일어난다.\n예시로, ls -al | wc -l | cat 와 같은 명령어를 입력하였을 때, command 별로 이를 [[&quot;ls&quot;, &quot;-al&quot;], [&quot;wc&quot;, &quot;-l&quot;], [&quot;cat&quot;]] 와 같이 parsing 해내고, 순차적으로 ls -al 명령을 실행하기 위해 fork 후 execvp 한 결과를 pipe_fd[1]에 넣고, pipe_fd[0]에서 wc -l이 이를 읽어와 fork 후 execvp 하여 실행한 결과한 pipe_fd[1]에 넣고, pipe_fd[0]에서 cat이 이를 읽어와 fork 후 execvp 한 결과를 최종적으로 stdout으로 출력한다. 즉 이와 같은 경우에서는 3번의 fork를 통해 프로세스가 실행되었다.\n이와 같은 과정을 거쳐 이전 프로세스의 출력이 파이프에 작성되고, 이를 다음 프로세스가 파이프에서 읽어와 pipelining이 구현될 수 있도록 하였다.\nLessons Learned §\n프로세스를 생성하는 과정에 대해서 알게 되었다. 단순히 exec를 통해 프로세스를 바로 실행하게 될 경우에는, 새로운 프로세스로 실행되는 것이 아닌, 현재 사용중인 프로세스에서 새로운 프로세스가 실행되는 것이기 때문에, 이전의 상태를 저장한 상태로 사용할 수 없다. 이를 위해 fork라는 과정을 거쳐 현재 프로세스를 그대로 복제한 자식 프로세스를 생성한 뒤, 자식 프로세스에서 exec를 통해 실행하게 된다. 자식 프로세스가 exit하면, wait을 통해 부모프로세스는 자식프로세스가 끝났음을 확인하고 그대로 동작을 진행할 수 있다.\n파이프라인으로 연결된 inter process communication 기법에 대해서도 직접 파이프 사용해보며 알 수 있었다. pipe file descriptor의 0번째 index는 pipe의 read end로 pipe에서 읽어오는 역할을, 1번째 index는 pipe의 write end로 pipe에 입력하는 역할을 한다. 파이프를 사용할 때, dup2를 이용하여 stdin의 입력을 pipe의 read end에서 입력받고, stdout의 출력을 pipe의 write end에 작성함으로써 pipe를 통하여 프로세스간 통신을 진행할 수 있었다. 디버깅 중에 가끔 프로그램이 가만히 멈춰있는 경우가 존재하였는데, 이는 파이프를 정상적으로 닫아주지 않아 EOF를 대기하던 상황이였음을 알 수 있었다."},"Projects/OS-Assignments/pa2":{"title":"PA2: Simulating Process Schedulers","links":[],"tags":["os","assignment","C"],"content":"https://github.com/parkjbdev/SCE213_OS/tree/os-pa2\nAbstract §\n이번 과제는 OS의 process scheduler를 구현하는 과제로, SJF scheduling, STCF scheduling, RR scheduling, Priority scheduling (including Basic Scheduling / Aging / Ceiling Protocol / Inheritance Protocol) 을 직접 구현하는 것이 목표이다.\nREADME.md에 주어진 각 스케줄러에 대한 testcases를 포함하여 주어진 모든 testcase에 대해서 올바른 결과가 나올 수 있도록 고안하였다.\n추가적으로, test*.sh file들은 컴파일과 실행이 정상적으로 종료되는지 확인하기 위해 작성한 스크립트이다.\nFIFO Scheduler §\nFIFO Scheduler는 first-in-first-out scheduler의 약자로, 프로세스가 ready된 순서대로 scheduling 해주는 policy 이다.\nFIFO Scheduler는 non-preemptive하게 동작하며, ready된 순서대로 스케줄링하기 때문에 starvation이 일어나지 않는다는 특징이 있다.\n하지만, 순차적으로 실행되는 특징 때문에, 비교적 lifespan 이 긴 프로세스가 lifespan 이 짧은 프로세스보다 먼저 스케줄링되는 경우, 전반적인 turnaround time 이 길어진다는 단점이 존재한다.\n이러한 단점을 보완하기 위해 lifespan 이 짧은 프로세스를 우선적으로 실행하는 SJF scheduling 방법을 이용할 수 있다.\nnon-preemptive 한 스케줄러이므로, current process 가 없어 아무것도 실행되고 있지 않은 경우에만 readyqueue 에 들어간 순서대로 scheduling 된다.\nSJF Scheduler §\nSJF Scheduler는 shortest-job-first scheduler의 약자로, 프로세스가 가장 먼저 끝나는 것을 우선적으로 실행하는 scheduling policy 이다.\nSJF Scheduler 역시 non-preemptive 하게 동작하는 scheduler 로, 한번 스케줄링되어 실행중인 process에 대해서는 중간에 다른 process 로 switch 하지 않는다. 하지만 FIFO scheduler 와는 달리 process 가 fork 된 순서가 아닌, shortest job process 를 우선적으로 스케줄링한다.\n이러한 특징으로 인해, lifespan이 짧은 프로세스가 계속해서 fork되었을 경우, lifespan이 긴 프로세스는 계속 대기하게 되는 starvation 현상이 나타날 수 있다.\nnon-preemptive 한 스케줄러이므로, current process 가 없어 아무 process 도 실행하지 않을 경우에 대해서만 shortest job을 찾는 과정을 통하여 scheduling 하여 구현은 간단하였다.\nSTCF Scheduler §\nSTCF Scheduler는 shortest-time-to-completion scheduler 의 약자로, non-preemptive 한 SJF Scheduler 를 개선한 preemptive 한 SJF scheduler 이다.\nSTCF Scheduler 역시 SJF Scheduler 와 마찬가지로, readyqueue 에 등록된 process 들 중에서 가장 먼저 끝나는 것을 가장 우선적으로 실행하는 scheduler 이다.\n따라서 SJF Scheduler 와 마찬가지로, 비교적 lifespan 이 짧은 process 가 계속하여 fork 된다면 작업을 끝내기까지 오랜시간이 걸리는 process 들은 계속 순위가 밀려 starvation 이 발생할 수 있다.\nPreemptive 한 scheduler 이기 때문에 앞선 두 scheduler 들과 달리, current process 가 실행중일 때에도 가장 먼저 끝날 수 있는 process 가 업데이트되어 달라지면, 해당 process 가 더 우선적으로 scheduling 될 수 있도록 하였다.\n초기 구현에서는 논리의 흐름이 보기 어려웠으나, 완성하고 다시 리팩토링을 진행한 결과, 결국 scheduler의 패턴들이 모두 비슷한 구조를 가지고 있음을 확인하였고, stcf 도 논리흐름이 더 잘보이도록 readable 하게 리팩토링하였다. (1dd4d6d)\n한가지 의문에 남았던 것은, 기존에 주어진 STCF Scheduler 의 주석에 forked 가 필요할 것이라고 주석을 통해 확인하였지만, 본인은 forked 함수의 구현 없이 scheduler 를 완성하였다는 점이다.\n현재 구현에서는 매 스케줄링마다 조건에 맞는 process 를 readyqueue 에서 순회하며 찾아서 scheduling 하였지만, forked 함수가 이용되는 로직이라면, 정렬된 readyqueue 를 이용하는 방식일 것으로 생각한다.\n프로세스가 생성될때마다 정렬된 readyqueue 에서 올바른 위치에 fork 된 프로세스를 옮겨주면, schedule 함수에서 readyqueue 를 순회하며 조건에 맞는 process 를 찾는 과정 없이 first_entry 를 뽑아 current process 와의 우선순위를 비교하여 scheduling 할 수 있기 때문이다.\n다만, 이렇게 readyqueue 를 관리한다면, SJF Scheduler 에 대해서도 마찬가지로 forked 함수가 필요할 것이다.\nRR Scheduler §\nRR Scheduler는 round-robin scheduler 의 약자로, 각 프로세스에게 동일한 time quantum 을 할당하여 scheduling 하는 scheduler 이다. 이번 프로젝트에서는 1tick을 하나의 time quantum으로 이용하였다. 기본적으로는 들어온 순서대로 1tick 씩 처리하며, process가 끝나지 않았다면 다음 차례에도 1tick씩 실행하기 위해서 readyqueue에 다시 배치된다.\n이러한 scheduling 방식으로 인해 round-robin scheduler는 preemptive 하며, starvation이 일어나지 않는다는 특징이 존재한다. 또, process의 response time 측면에서 이득을 볼 수 있다는 장점이 존재한다.\n이러한 특징을 가진 RR Scheduler의 구현은 STCF보다도 쉽게 구현할 수 있었다.\npreemptive한 fifo scheduler라고 생각할 수 있기 때문에, 큰 틀은 이와 유사하게 구현할 수 있었으며, 대신 1 tick 씩만 실행되고 readyqueue의 tail에 다시 저장할 수 있도록 구현하였다.\n초기에 RR Scheduler 를 구현할 때에는 이러한 FIFO Schedule 와의 공통적인 특징을 미처 생각하지 못하고, 논리흐름은 유사하지만 다른 코드로 구현하였다. 하지만, 이러한 공통적인 특징을 파악하고, 논리흐름을 더 직관적으로 이해할 수 있는 FIFO Scheduler 의 코드를 일부 재사용하여 재구현하였고, 출력결과는 모든 테스트케이스에 대해서 같음을 확인하였다. (955d15b1)\nPriority Scheduler §\nPriority Scheduler는 각 process의 priority 에 따라 scheduling 하는 순서가 결정되는 방식의 scheduler 이다.\n이번 프로젝트에서는 prio 멤버 변수의 크기가 클수록 더 높은 priority 를 가진 process 로 규정하였으며, readyqueue 에 대기하는 process 들 중에서 가장 높은 priority 를 가진 process 를 매 스케줄링마다 뽑아서 반환해주도록 하였다.\n즉, preemptive 한 형태의 priority scheduler 이다.\n또, 같은 priority 를 가진 process 들에 대해서는 rr scheduling 을 해주는 것이 목표이다.\n이번 priority scheduler의 구현에서 혼동되는 개념들과 잘못된 구현으로 인한 메모리 에러 및 assertion failure 때문에 초반에 난항을 많이 겪었다.\n특히 resource 를 acquire 하고 release 하는 과정에서 혼동이 많았는데, 처음 구현할 당시에 가장 크게 헷갈렸던 부분은 resource 를 acquire 하고 release 하는 과정에서 어느시점에 release 를 진행해야 하는지였다.\n우선 처음 잘못 이해한 priority scheduler 에서는, 만약 리소스가 이미 다른 더 우선순위가 낮은 프로세스에 의해 사용중인 상태일 때에는, 강제로 해당 리소스를 release 시키고서라도 priority 가 더 높은 프로세스에게 우선적으로 scheduling을 진행해 줄 수 있도록 해야한다고 생각하였다.\n하지만 이는 priority inversion에 대한 내용을 정확하게 숙지하지 못한 결과이다.\n만약, 우선순위가 더 높은 프로세스가 언제든 강제로 우선순위가 더 낮은 프로세스의 resource 를 뺏어와 우선순위가 더 높은 프로세스로 preempt 할 수 있었다면, priority inversion 과 같은 문제는 일어나지 않았을 것이다.\n하지만, 리소스의 특성상, 이미 사용중인 리소스에는 다른 프로세스가 접근하여 동시에 사용할 수 없기 때문에 강제로 리소스 사용을 해제하게 된다면, 이전에 리소스를 사용하여 진행하였던 tick들을 다시 진행해야 하는 상황이 발생한다.\n또, 더 높은 우선순위를 가진 process A가 resource 를 acquire 하였을 때, 낮은 우선순위를 가진 process B 에 의해 block 당했다면, block 시킨 process B 를 실행시켜야 더 높은 우선순위를 가진 프로세스A 가 우선적으로 실행될 수 있다고 생각하여, process B 로 스케줄링을 진행하려 하였다.\n하지만, 이런 스케줄러가 존재한다면, priority inversion 이 존재하지 않는 스케줄러가 되었을 것이다. 이 역시 priority inversion 에 대해서 잘못 이해하여 생긴 결과였다.\n두번째로 또 잘못 구현하였던 것은 readyqueue에서 PROCESS_READY state 에 있는 프로세스와 r-&gt;waitqueue 에서 PROCESS_BLOCKED state 에 있는 프로세스들을 혼용한 점이다.\nresource 를 요청하였지만 블락당한 프로세스들은 r-&gt;waitqueue 에 등록을 해주어 해당 리소스가 release 될 때에 다시 readyqueue 에 추가되어 scheduler 에서 자연스럽게 scheduling 될 수 있도록 해주어야 하는데, priority inversion에 대한 미숙한 이해와 이미 구현된 framework 의 이해 부족으로 scheduler 에서 직접 리소스들에 접근하려는 방법역시 시도하였지만, 사용이 제한된 함수여서 그렇게 하지 못하였다.\n그렇게 resource의 release 와 acquire 등에 대한 고민들에 대해서 다시 공부하고 QnA 등을 통해 해결하여 성공적으로 testcase를 통과할 수 있었다.\n막상 구현을 완성하고 모든 testcase를 통과하였더니 생각했던 것보다는 단순한 코드를 확인할 수 있었다. 이때의 논리흐름을 가독성있게 다시 정리하여 표현하여 보았더니 (1e77af93), rr_schedule 과 한라인을 제외하고 사실상 동일한 코드가 나옴을 확인할 수 있었다.\nrr_schedule 에서는 priority 에 대한 고려없이 스케줄링을 해주어 단순히 readyqueue 의 첫번째 엔트리를 스케줄링 하였지만, prio_schedule 에서는 priority 가 가장 높은 프로세스를 직접 구현한 find_process 함수를 통해 찾아 스케줄링 해주는 부분이 유일하게 다른 점이였다.\n위의 이해한 내용들을 바탕으로 resource를 acquire 하는 함수 prio_acquire 를 구현해 본 결과, 사실상 fcfs_acquire 와 같은 코드를 쓰고 있는 것을 발견하게 되었다.\nacquire 의 경우 resource 의 waitqueue에 등록될때 우선순위가 바뀌는 과정이 존재하지 않는다면, (ex. PIP/PCP Schedulin, aging의 경우 스케줄링 되면 prio가 초기상태로 돌아가므로 제외..) 그 과정은\n\n\n\n리소스 점유중이지 않으면 할당\n\n\n리소스가 점유되고 있는 중이면 해당 리소스의 waitqueue에 등록\n\n\n\n과 같은 과정으로 동일하게 나타난다.\nresource를 release 하는 함수 prio_release 역시 fcfs_release 와 거의 유사한 형태로, fcfs_release 는 단순히 waitqueue 에서 가장 첫번째 엔트리를 readyqueue 에 등록해준 반면, prio_release 는 waitqueue 에서 가장 우선순위가 높은 process를 readyqueue 에 등록해준다는 점에서만 차이가 존재하였다.\n이러한 시행착오들을 거쳐 구현을 완성하여 모든 testcase들을 통과할 수 있었다.\nPriority + Aging §\nPriority Scheduling with Aging은 말 그대로, 1 tick 이 흐를 때마다 readyqueue 에서 대기중인 프로세스들의 prio 를 1씩 높여주고, 스케줄링된 process의 경우 원래의 prio로 다시 초기화하는 방식을 채택한 priority scheduler 이다.\n이러한 방법을 이용하면, 기존의 priority scheduler에 비해서 starvation 을 예방할 수 있다는 장점이 존재한다.\n기본적인 틀은 기존의 priority scheduler와 동일하며, pa_schedule 에서도 prio_schedule 을 이용하여 다음에 실행될 프로세스를 scheduling 한다.\n다만, 스케줄링 받지 못한 프로세스들은 모두 prio 를 aging 시킨다는 점이 유일한 차이이다.\n기존의 priority scheduler를 이용한 scheduler 인지라, 구현은 간단하였다.\n구현 초반에 prio가 모두 1씩 높아지면, 당연히 서로의 우선순위간의 차이가 발생하지 않을 것이라 생각하고, 새로운 process가 fork 되는것이 아닌이상, aging이 무슨 의미가 있는것인지 생각하였는데, current를 제외하여 aging되며, scheduling 받는순간 원래의 priority로 돌아간다는 사실을 간과하고 있어서 발생한 문제였다.\n이를 인지하고, testcase들을 직접 계산해보았더니 이러한 priority aging scheduling을 이용하면, 아무리 priority가 제일 낮은 프로세스더라도, 계속하여 그 priority가 높아져 1tick 이라도 실행하여 starvation을 방지하는 것을 확인할 수 있었다.\nPriority + Ceiling Protocol §\nPriority Scheduling with Ceiling Protocol은 priority inversion을 방지하기 위한 해결책 중 하나로, priority가 더 높은 process가 요청한 resource가 block 당할 경우 priority inversion이 일어나지 않도록 기존에 resource를 점유하고 있는 process의 priority를 일시적으로 최대 priority로 boosting 하는 기법이다.\n또, 기존에 점유하고 있던 resource가 없어 acquire 하였다면, 자신의 priority 역시 최대로 boosting 하여 가장 우선적으로 끝날 수 있도록 한다.\n일시적인 priority boosting 이므로, 점유하고 있던 리소스를 release 할 때에는 원래의 priority로 돌아가게 된다.\npriority scheduling에 기반한 스케줄러에 resource 를 acquire 할 때, prio를 ceiling 으로 boosting 해주는 부분, resource 를 release 할 때, prio를 원래의 prio_orig 로 다시 돌려주는 과정만 추가해주면 되어서 구현에 어려움은 없었다.\nPriority + Inheritance Protocol §\nPriority Scheduling with Inheritance Protocol 역시 Ceiling Protocol와 함께 priority inversion을 방지하기 위한 해결책으로, block 시킨 더 낮은 우선순위를 가진 프로세스를 ceiling protocol과는 달리 최대 priority로 boosting 하지 않고, resource를 요청한 더 높은 프로세스의 priority를 상속받아 boosting하는 기법이다.\npip scheduling에서도 pcp scheduling과 마찬가지로, resource를 release 할 때에는 원래의 priority로 돌아와서 원래의 우선순위에 맞게 scheduling 될 수 있도록 한다.\npriority scheduling에 기반한 스케줄러에 resource 를 acquire 할 때, prio를 resource를 요청한 process의 priority로 설정해주는 부분과, resource 를 release 할 때는 ceiling protocol과 같은 과정으로 같은 함수를 이용하면 되어서 구현에 어려움은 없었다.\ntestcases/resources-adv2 을 실행하였을 경우 각 프로세스의 priority와 실행순서는 아래의 표와 같이 나타난다.\n아래으 표에서 priority를 표기할 때에, resource의 waitqueue에 존재하는 프로세스들은 [‘해당 리소스 번호’] ‘priority’ 와 같이 표기하였으며, priority 만 표기된 프로세스들은 모두 readyqueue에 존재하는 프로세스들이다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntickProcess #1prioProcess #2prioProcess #3prioProcess #4prio0Nresource #1 acquired (1/2)resource #2 acquired (1/3)resource #3 acquired (1/4)resource #4 acquired (1/4)Run (1/4)010Nresource #1 blockedinherit prio to process #1525waiting resource #1[1] 5N10Nresource #1 blockedinherit prio to process #1303resource #1 (2/2)resource #2 (2/3)resource #3 (2/4)resource #4 (2/4)Run (2/4) resource #1 released→ adding process #4 to readyqueue30[1] 510Waiting resource #1[1] 3040[1] 510resource #1 acquired (1/1)Run (1/1)resource #1 released→adding process #2 to readyqueue30505Run 1/410Done605Run 2/410705resource #2 blockedinherit prio to process #1108resource #2 (3/3)resource #3 (3/4)resource #4 (3/4)Run (3/4)resource #2 released→ waitqueue is empty105waiting resource #2[2] 10905resource #2 acquired (1/2)Run 3/4101005resource #2 (2/2)Run 4/4resource #2 released10110resource #1 acquired (1/2)Run (1/3)5Done120resource #1 (2/2)resource #2 acquired (1/1)Run (2/3)resource #1 released→ waitqueue is emptyresource #2 released→ waitqueue is empty5…계속…\nLessons Learned §\n\nResource Acquistion 과 priority inversion 에 대한 이해가 부족하였지만, 이번 프로젝트를 통해 언제 resource 를 acquire 하고, release 할 때의 동작, block 당했을 때의 후속 동작 등을 직접 구현하면서 priority inversion 을 완벽하게 이해할 수 있었다.\npriority aging을 구현하면서 각 프로세스들의 priority 가 점점 높아져 1tick이라도 scheduling 되는 모습을 확인하였다. 이를 통해 starvation을 방지하는 과정을 확인하였다.\n올바르게 다시 이해한 priority inversion 내용에 바탕하여, 이러한 문제를 방지하기 위한 priority boosting 을 위한 ceiling protocol, inheritance protocol을 구현해보았다. testcases/resources-adv2 를 이용하여 기본 priority scheduling과 priority inheritance protocol 이 적용된 priority scheduling 의 실행결과를 비교해 보았다. (diffcheck 결과)\n그 결과, priority scheduling 의 3tick 에서 priority inversion이 발생하는 것을 확인할 수 있었고, inheritance protocol 을 적용하였을 때에는 priority 가 더 높은 process 4의 실행을 위해 process 1에게 priority를 상속해주었더니, priority inversion이 발생하지 않는 것을 확인할 수 있었다.\n프로그램을 작성할 때에, goto 문의 사용을 지양하고 기피하였는데, 이번 프로젝트에서는 이를 사용하지 않았을 때 오히려 가독성이 떨어지고 logic 의 흐름을 알아차기가 어려운 면이 존재하였다.\n모든 스케줄러들을 완성한 이후에 기존의 주어진 goto문이 사용된 fcfs_schedule 코드의 스타일을 적용할 수 있을지 각각의 스케줄러들을 다 확인하면서 최대한 유사한 구조로 리팩토링을 한 결과, 비슷한 구조로 적용이 가능했고, 더 readable 한 코드를 얻을 수 있었다.\n따라서 goto 문의 무조건적인 기피보다 필요에 따라 적절히 활용하여 더 효율적으로 작성이 가능하다면 이를 채택하고 사용하여도 되겠다는 생각이 들었다.\n"},"Projects/OS-Assignments/pa3":{"title":"PA3: Virtual Memory Simulator","links":[],"tags":["os","assignment","C"],"content":"https://github.com/parkjbdev/SCE213_OS/tree/os-pa3\nAbstract §\n이번 과제는 virtual memory simulator로, 프로세스가 읽을 수 있는 logical address (혹은 virtual address) 를 physical address로 변환해주는 MMU의 역할 중 일부를 수행하는 프로그램을 작성하는 것이다.\nLogical address는 Virtual Page Number (혹은 VPN)와 Offset으로 나뉘고, MMU가 Page Table을 참조하여 VPN을 Page Frame Number (혹은 PFN)로 바꾸면 실제 Page가 저장되어 있는 Physical Address를 알아낼 수 있다.\n이번 과제에서는 2 level hierachical page table을 사용하며, page table을 가리키는 outer page table가 정의되어있다.\n즉, VPN을 두 부분으로 나누어 각각 outer page table의 index 와 page table의 index를 알아내어 VPN에 해당하는 PTE (Page Table Entry)를 찾아 PFN을 알아낼 수 있도록 한다.\nPage Allocation §\n주어진 vpn에 대해서 새로운 page를 할당하는 과정이다.\n초기 구현과정에서 과제의 specification에 대해 혼동이 있어, vpn을 pfn으로 바꿔주는 것이 아닌, offset이 포함된 전체 virtual address를 pfn과 offset이 합해진 physical address로 바꾸어 주는 절차로 생각하였으나, virtual page number의 정의에 대해서 다시 생각해본 결과, virtual address의 offset은 고려하지 않아도 되는 사항임을 확인하였다.\ncommit 2b08f40: Implement alloc_page and free_page §\nallocation 을 진행할 때, 주어진 vpn에 대해 해당하는 pd_index와 pte_index를 찾아 해당하는 page table entry에 접근해야 한다.\n이를 위해서, 처음에는 비트 이동 연산자 &gt;&gt; 와 &lt;&lt;을 이용하여 다음과 같이 연산하는 방법을 고려하였다.\npd_index = vpn &gt;&gt; PTES_PER_PAGE_SHIFT;\npte_index = vpn &lt;&lt; (32 - PTES_PER_PAGE_SHIFT) &gt;&gt; (32 - PTES_PER_PAGE_SHIFT); // unsigned int uses 32bits\n여기에서 고려하지 않아도 되는 offset까지 고려하려고 하는 바람에 (사실 offset bit이 몇 bit을 차지하는지 알 수도 없다.) 비트연산자로 계산이 복잡해지고, 올바른 방법인지 의심하던중, vm.c의 __translate 함수에서 vpn을 NR_PTES_PER_PAGE로 나눈값과 나눈 나머지의 값으로 index를 알아내는 것을 확인후에, 올바르게 접근하는 방법을 알 수 있었다.\n위의 방법을 사용하여 pd_index와 pte_index를 알아낸 이후, pte_directory가 NULL로 선언되지 않은 상황일 때, 동적으로 할당해준 뒤에 올바른 page table entry들의 값을 할당해주며 초기화해주었다.\ncommit 88c1a07: implement: handle_page_fault §\nread only page에 write를 시도할 경우, page fault가 발생하여 page fault handler가 동작한다.\n이러한 상황에서, 이전에는 rw의 초기상태를 알 수 없어서, 해당 page가 read권한만 있는지, write권한도 있는지를 알 수 없었다.\n이를 page fault handler에서 알 수 있게 하기 위해, 이전의 pte의 private멤버에는 아무것도 할당하지 않았으나, rw의 초기상태를 allocation 과정에서 저장해 주기로 하였다.\nPage Deallocation §\n주어진 vpn에 대해 해당하는 pte를 해제시켜주는 과정이다.\nalloc_page에서와 같은 방식으로 pd_index와 pte_index를 계산하여 올바른 page table entry를 찾아간 뒤, valid bit을 false로 바꿔주는 과정이 주요한 요소이다. 이때, 해당하는 pfn을 referencing 하는 프로세스가 하나 줄어든 것이므로, mapcounts[pfn]의 값도 1만큼 감소시켜준다.\ncommit 2b08f403: Implement alloc_page and free_page §\n초기에 구현할 때, pte에 대한 혼동이 있어, 다른 프로세스도 공유한다고 생각하였는지, 현재 프로세스만 유일하게 해당 page frame을 참조하고 있을 때, valid bit을 false로 변경하는.. 코드를 작성하였는데, 이는 버그이다.\n당연하게도, 각 프로세스마다 pagetable이 따로 존재하며, free를 한다는 것은 더이상 해당 page table entry가 valid하지 않은 entry라는 것이기 때문에, 그러한 조건을 확인할 필요 없이, valid bit을 false로 바로 바꾸어주면 된다. 이는 commit d89cd9e6에서 수정되었다.\nFork §\n새로운 프로세스를 생성할 때, switch_process에서 fork하는 과정을 거쳐 생성한다.\n즉, 새로운 프로세스를 생성할 때, 기존 프로세스에서 사용된 모든 메모리 정보들이 새로운 프로세스에 똑같이 복사된다.\n이번 fork에서는 process dependent 한 정보인 pid와 list 멤버는 올바른 값으로 초기화시켜주고, pagetable을 그대로 복사해 주었다.\npagetable을 복사하기 전 Copy on write의 구현을 위해 전처리하는 과정을 거친다. 그 과정은 추후 자세히 설명한다.\n기존에 switch하려던 process가 존재하지 않을 경우 위와 같이 fork를 진행하며 pagetable을 복사해야 한다.\n이 과정을 처음에는 단순히 memcpy를 이용하여 복사하였으나, 이렇게 복사할 경우 pagetable을 shallow copy 한 것이 되어, 서로 다른 process 이더라도 같은 주소값을 참조하는 결과를 디버깅을 통해 확인하였다.\n따라서 이를 해결하기 위해 malloc을 통해 다시 동적으로 메모리를 할당하며, outer_pte와 ptes 모두 다른 주소공간에 같은 값을 복사할 수 있도록 pagetable을 deep copy해주는 함수 clone_pagetable을 통해 pagetable을 복제하여 새로운 프로세스에 할당해주었다.\n이 과정역시 copy on write을 이용하여 구현할 수는 있겠으나, 구현의 복잡성 때문에 우선 단순 deep copy하는 방식을 취하였다.\nCopy on Write §\n우선 다른 얘기이지만, Apple WWDC 2017에서 새롭게 소개된 APFS 파일 시스템을 소개할 때, copy on write이라는 것을 처음 접해보았다.\n당시에, 이러한 방법을 사용하면 파일을 논리적으로 복사할 때 속도도 빠르고, 물리적인 저장공간도 적게 사용할 수 있다는 점에서 센세이셔널하게 느꼈던 기억이 있다.\n약 6년이 지나고 운영체제 수업을 들으며 copy on write을 오랜만에 다시듣고, 간단하게 구현해보게 된다는 점에서 개인적으로 흥미를 느꼈다.\nAPFS의 Storage 차원의 CoW와 달리, 이번 과제에서의 CoW은 Memory 단에서 동작한다.\n말 그대로, copy on write은 copy를 lazy하게, write을 시도할 때 그제서야 copy를 하는 방법을 뜻한다. 그 구현은 다음의 일련의 과정과 같다.\n\nprocess fork를 시도하면, pte들의 rw bit을 read-only하게 바꾸어준다.\n그리고, 같은 page table을 deep copy하여 새로운 프로세스에 할당해 주면, 서로 다른 pagetable에서 같은 pfn을 참조한다.\n하지만, 부모 프로세스와 자식 프로세스 모두 pte의 rw bit이 read-only 하기 때문에, write을 시도할 경우 page fault가 발생한다.\n이와 같이 page fault가 발생할 경우, page fault handler에서 해당 page frame을 참조하는 프로세스의 개수(mapcounts)를 확인한다.\n\nmapcounts[pfn] == 1일 경우는 현재 프로세스만 해당 page frame을 참조하고 있는 상황으로 기존의 rw 권한을 복구시켜 준다.\nmapcounts[pfn] &gt; 1일 경우, 현재 프로세스 외에 다른 프로세스도 해당 page frame을 참조하고 있는 상황으로, page frame에 함부로 write 할 경우, 다른 process에 영향을 미치게 된다. 따라서, 새로운 page frame에 기존의 page frame을 복사하여 새로운 page frame을 참조하도록 pfn을 변경해준다.\n\n\n\n이를 구현하기 위해, switch_process의 fork 과정에서, pagetable을 복사하기 전에, valid한 pte에 대해서 mapcounts[pfn]을 1증가시키고, rw bit을 read-only하게 변경해준뒤, pagetable을 새로운 process에 deep copy 해주었다.\nhandle_page_fault에서는 read-only page에 write을 시도하여 page fault가 발생하였을 때, 위에서 언급한대로 핸들링하였다.\n즉, commit 39eb584d와 88c1a070이 사실상 copy on write을 구현한 commit이라고 보아도 무방하다.\nTestcase: testcases/cow-2 §\n우선, testcases/cow-2의 경우, NR_PTES_PER_PAGE=16을 넘어가는 vpn 주소의 할당은 없다.\n따라서, 모든 vpn의 outer_ptes는 0번째 ptes가 되므로 편의를 위해 outer_ptes에 대한 언급은 가급적 생략하도록 하겠다.\nallocation (@process#0) §\n먼저, process#0에서 vpn 0(r) 1(r) 2(rw) 3(rw)의 allocation이 진행된다.\n앞에서 언급했듯이, outer_ptes의 index는 0이고, 0번째 ptes는 다음과 같이 구성된다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Trw2rw3Trw3rw\nswitch (process#0 → process#1) §\nprocess#0 에서 process#1로 현재 실행중인 프로세스가 변경되었다.\n이때, process#1은 이전에 실횅된 적이 없는 프로세스로, process#0를 fork하여 새로운 프로세스를 만들게 된다.\n그 결과, process#1의 pagetable은 process#0의 pagetable과 같은 값을 가진다.\n다만, copy on write을 위해서, process#0의 pagetable을 process#1로 복사하기 전에 pte가 모두 ACCESS_READ 권한만 가지도록 하여, write을 할 수 없도록 한다.\n만약, 추후 write을 시도한다면, page fault가 발생하는데, 이때, page fault handler가 mapcounts를 확인하여 해당 page를 reference 하고 있는 process가 여러 개일 경우, 새로운 pfn을 할당 및 복사하여 해당 page frame에서 write이 가능하도록 변경한다.\n따라서, process#0과 process#1의 pte는 fork 된 후 다음과 같이 변경 혹은 할당된다.\npagetable of both process#0 and process#1 (identical) after switch 1 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Tr2rw3Tr3rw\nread &amp; write on process#1 §\nprocess#1의 read 1의 경우 read 권한이 있으므로 문제없이 동작한다.\nprocess#1의 write 2의 경우 fork를 하면서 write 권한이 사라졌기 때문에, 앞에서 언급했듯, page fault handler가 기존에 write가 가능한 page인지 확인 후, 가능하다면 새로운 pfn을 찾아서 할당 및 복사해준다.\n이번 경우, pfn 4번이 비어있는 가장 빠른 pfn이므로, 기존 2번의 page frame을 4번의 page frame에 복사하여 write 권한을 부여한다.\n따라서, process#1의 pte는 다음과 같이 변경된다.\npagetable of process#1 after read 1 and write 2 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Trw4rw3Tr3rw\nswitch (process#1 → process#2) §\nprocess#1 에서 process#2로 현재 실행중인 프로세스가 변경되었다.\n마찬가지로, process#2은 이전에 실횅된 적이 없는 프로세스로, process#0를 fork하여 새로운 프로세스를 만들면, read권한만 있는 pte들이 복사되어 다음과 같다.\npagetable of both process#1 and process#2 (identical) after switch 1 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Tr4rw3Tr3rw\nread &amp; write on process#2 §\nprocess#2에서 read 1을 시도하면, 위의 pagetable에서 1번째 index pte를 거쳐 문제없이 읽을 수 있다.\nprocess#2에서 write 3을 시도하면, 3번째 index pte는 read 권한만 가지고 있기 때문에 page fault가 발생하고, page fault handler가 기존 권한을 확인한 후 새로운 pfn를 찾아서 할당해준다.\n이번 경우, pfn 5번이 비어있는 가장 작은 pfn으로, 다음과 같이 pagetable이 변경된다.\npagetable of process#2 after read 1 and write 3 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Tr4rw3Trw5rw\nswitch (process#2 → process#0) §\nprocess#0은 기존에 생성되어 있던 프로세스로, processes에서 불러온다.\nprocess#0의 마지막 상태의 pagetable은 다음과 같았다.\npagetable of process#0 after switch 0 (loads last state of process#0’s pagetable) §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Tr2rw3Tr3rw\n이때, read 2의 경우 정상적으로 pagetable을 확인하여 읽어올 수 있다.\nwrite 2를 할 경우, 2번 index는 read권한만 있기 때문에, page fault가 발생하여 page fault handler가 동작한다.\n하지만, mapcounts 배열에서 pfn 2를 참조하는 process가 자신으로 하나뿐이기 때문에, rw 권한으로 바꾸어도 다른 프로세스에 영향을 미치지 않는다.\n따라서 rw 권한으로 바꾼 뒤, pfn 2에 write을 한다.\npagetable of process#0 after write 2 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Trw2rw3Tr3rw\nwrite 3을 할 경우, 3번 index는 read 권한만 있기 때문에, page fault가 발생하여 page fault handler가 동작한다.\n2번 pfn과 달리 3번 pfn의 경우 현재 process#1 역시 참조하고 있는 상황이기 때문에 mapcounts에서 확인한 reference count는 2가 되며, 이에 따라 새로운 pfn을 할당해주어야 한다.\n따라서, 가장 작은 사용하지 않은 pfn인 6번을 할당후 rw권한을 부여해서 write를 할 수 있도록 변경된다.\n위와 같은 과정을 거친 process#0의 pagetable은 다음과 같다.\npagetable of process#0 after write 3 §\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nindexvalidrwpfnprivate0Tr0r1Tr1r2Trw2rw3Trw6rw\n결국, 세 프로세스의 최종 pagetable의 상태는 다음과 같이 구성된다.\n\n  \n  process#0\n  process#1\n  process#2\n    \n      \n      \n      \n      index\n      valid\n      rw\n      pfn\n      private\n      \n      \n      \n      \n      0\n      T\n      r\n      0\n      r\n      \n      \n      1\n      T\n      r\n      1\n      r\n      \n      \n      2\n      T\n      rw\n      2\n      rw\n      \n      \n      3\n      T\n      rw\n      6\n      rw\n      \n      \n      ...\n      \n      \n      \n      \n      \n      \n      15\n      F\n      \n      \n      \n      \n      \n      \n    \n    \n      \n      \n      \n      index\n      valid\n      rw\n      pfn\n      private\n      \n      \n      \n      \n      0\n      T\n      r\n      0\n      r\n      \n      \n      1\n      T\n      r\n      1\n      r\n      \n      \n      2\n      T\n      rw\n      4\n      rw\n      \n      \n      3\n      T\n      r\n      3\n      rw\n      \n      \n      ...\n      \n      \n      \n      \n      \n      \n      15\n      F\n      \n      \n      \n      \n      \n      \n    \n    \n      \n      \n      \n      index\n      valid\n      rw\n      pfn\n      private\n      \n      \n      \n      \n      0\n      T\n      r\n      0\n      r\n      \n      \n      1\n      T\n      r\n      1\n      r\n      \n      \n      2\n      T\n      r\n      4\n      rw\n      \n      \n      3\n      T\n      rw\n      5\n      rw\n      \n      \n      ...\n      \n      \n      \n      \n      \n      \n      15\n      F\n      \n      \n      \n      \n      \n      \n    \n  \n\n\n다시한번 그 과정을 도식화하면 다음과 같다.\n\nTLB §\nTLB는 Translation Look-aside Buffer을 줄인말로, principle of locality 특성 때문에 이전에 읽거나 쓴 값은 앞으로도 읽거나 쓸 가능성이 높아 buffer에 해당 pte에 관한 정보를 적어두어 pagetable을 직접 참조하지 않고도, pte에 더욱 빠른 접근을 가능하게 하는 buffer이다.\n본래 의도는 pte에 더욱 빠르게 접근하기 위한 것이지만, 이번 과제에서는 tlb에서 일치하는 vpn을 찾는 과정에서 for loop을 거치기 때문에, 오히려 더 느릴 가능성이 존재하기는 하다.\n다만, 간단한 시뮬레이터임을 가정하므로 이러한 차이는 우선 무시하도록 한다.\nTLB를 구현할 때, process간 스위치가 되었을 경우에 대해 TLB를 어떻게 update 시켜야 할지에 대한 고민이 있었다.\nprocesss를 switch 할 때, 이전의 pid를 private 멤버에 저장하는 방법으로 즉, Address-Space Identifiers (ASIDs) 를 이용하는 방법도 존재하고, 그냥 tlb flush 시키는 방법도 있기 때문이다.\n하지만 결국 구현의 편의 때문에 tlb flush 시키는 방법을 선택하였다.\n또, 이번 과제에서는 입력이 적어 고려되지 않았지만, TLB entry가 NR_TLB_ENTRIES를 넘어 victim을 골라야 하는 상황이 발생할 수 있다.\n이러한 경우가 생긴다면, Belady’s Algorithm, FIFO, LRU 등등의 방법을 이용하여 victim page를 선택하여 해당 tlb entry 를 free시켜 사용하면 될 것이다.\nread 혹은 write operation을 하였을 때, 해당 vpn이 tlb에 적혀있는지 lookup_tlb를 통해서 참조하는 과정을 거친다.\n만약 해당 vpn에 대한 tlb entry가 존재하고, rw bit을 참조하여 허용되는 operation일 경우, tlb hit 된것으로 판단하여 tlb에 적혀진 pfn을 보고 MMU가 vpn을 변환하게 된다.\n하지만 tlb hit이 나지 않았을 경우, 추후에 참조할 가능성을 고려해서 tlb에 pte의 정보를 작성해주어야 한다.\n이를 위해서 먼저 주어진 vpn에 매칭하는 pte를 찾아 rw bit, pfn 값 등을 참조한다.\n이렇게 읽어온 값들을 insert_tlb에서 tlb에 삽입 혹은 update하게 되는 과정을 구현하면 tlb에 대한 주요 구현은 마무리 되었다.\n하지만, 사소하게 신경써주어야 하는것들로, pte의 값들이 바뀌었을 때, tlb의 값도 변경해서 update 해주어야 한다는 점이다.\n이번 과제의 경우, testcase에서 이를 검출하는 case는 존재하지 않아 문제없이 통과하였지만, 이를 고려하지 않는다면, page fault가 난 이후 write 하는 과정에서 tlb와 pte에 저장된 rw bit이나 pfn 값이 달라 문제가 발생할 수 있다.\n이러한 문제점을 인지하고, commit 253cc7f7에서 수정하였다.\n추후, vm.c를 확인하였는데, __translate 에서 insert_tlb를 통해서 tlb를 update 해주는 과정이 존재하는 것을 확인하고, 해당 코드를 삭제하였다.\ncommit f7f01b80: cleanup &amp; add comments §\n우선, pd라는 변수의 이름이 잘 와닿지 않아, 어려움이 있었는데, 결국 최종 pte를 알아내기 전의 마지막 page table 이므로, pt로 이름을 변경하였다.\n그리고, DRY(Don’t Repeat Yourself) 원칙과 readability를 위해서, pt와 pte를 구하는 과정을 get_pt와 get_pte라는 새로운 함수를 만들어 사용하였다.\nLessons Learned §\n\n이번 과제를 통해서 memory management unit이 pagetable을 조회하며 vpn을 pfn으로 변환하는 과정을 구현하며, vpn에 해당하는 pte를 어떻게 찾아가는 과정을 알 수 있었다.\n새로운 process를 fork할 때, shared memory를 사용하여 메모리를 효율적으로 사용하게 된다. 하지만, write을 할 때에는, 서로 다른 process 공유하고 있는 메모리에 작성할 경우 문제가 된다. 따라서, fork하는 process의 pte를 모두 read only page로 바꾸어준 뒤, write을 시도하여 page fault가 발생하면 handler가 그제서야 해당 page를 copy 해주는 방식인 Copy on write을 이용하였다. 또, 이런 과정을 거쳐, 해당 page를 참조하는 process가 결국 하나가 되었을 경우에는 다시 기존의 rw bit을 복구시켜주었다.\nTLB 를 이용하여 page table entry를 더욱 빨리 찾을 수 있는데, read 혹은 write 명령이 발생할 때마다, 이전에 TLB에 등록된 적이 없는 vpn이라면, TLB에 등록시키는 과정을 구현하였다. 또, 주어진 vpn과 rw 상태에 대해서 tlb hit이 나는지 판별하는 과정을 구현하였다. TLB를 이전에는 마냥 pagetable을 캐시해둔 것으로 추상적으로 알고 있었지만, 언제 등록되는지에 대해서는 자세히 알지 못하였다. 물론 실제 운영체제에서는 더 복잡한 조건이 있을 수 있지만, 이번 과제를 통해서 간단하게나마 알 수 있었다.\n\n"},"Projects/WePlan/01_Project-Proposal":{"title":"Project Proposal","links":[],"tags":["report"],"content":""},"Projects/WePlan/02_Requirements-Specification":{"title":"Requirements Specification","links":[],"tags":["report"],"content":""},"Projects/WePlan/03_Design-Document":{"title":"Design Document","links":[],"tags":["report"],"content":""},"Projects/WePlan/04_Final-Project-Report":{"title":"Final Project Report","links":[],"tags":["report"],"content":""},"Projects/WePlan/index":{"title":"WePlan - 공동공간 예약 서비스","links":[],"tags":["flutter","spring","keynote"],"content":"\n\nWePlan은 동아리의 공용공간 사용에 대한 일정관리 및 공유를 용이하게 해주는 서비스입니다.\n\n\n\nconst setRepoTheme = (theme) =&gt; {\n\tconst elems = document.querySelectorAll(&#039;.repo-card&#039;)\n\tfor (const elem of elems) {\n\t\tif (theme === &#039;dark&#039;)\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;dark-theme&#039;)\n\t\telse\n\t\t\telem.setAttribute(&#039;data-theme&#039;, &#039;light-default&#039;)\n\t}\n\twindow.tarptaeya.reloadRepoCards()\n}\nsetRepoTheme(document.documentElement.getAttribute(&#039;saved-theme&#039;))\ndocument.querySelector(&#039;#darkmode-toggle&#039;).addEventListener(&#039;change&#039;, (e) =&gt; setRepoTheme(e.target.checked ? &#039;dark&#039; : &#039;light&#039;))\n"},"index":{"title":"Welcome!","links":[],"tags":[],"content":"\n\n\n\nProgramming Languages §\n\n\n\n\n\n\n\nFrameworks, Platforms and Libraries §\n\n\n\n\nSevers &amp; Databases §\n\n\n\n\n\n\nEnvironments &amp; Tools §\n\n\n\n\n\n\n\n\n\n\n\n\n학력 §\n\n2015.03 ~ 2018.02 단국대학교 사범대학 부속고등학교 졸업\n2018.03 ~ 2025.02 아주대학교 전자공학과 졸업예정\n2018.03 ~ 2025.02 아주대학교 소프트웨어학과 졸업예정\n\n경력 §\n\n2020.03 ~ 2020.08 한양대학교 의과대학 김이석 교수님 인턴연구원\n2022.07 ~ 2022.12 한양대학교 병원 정보관리팀\n2023.07 ~ 현재 아주대학교 System Software Lab 김상훈 교수님 인턴연구원\n\n수상내역 §\n\n2022.02.23. 디지털 신기술 혁신공유대학 미래자동차 가상환경기반 자율주행 경진대회 대상\n2022.06.08. 국제대학생 자율주행 경진대회 NVIDIA특별상 – 금상\n2022.06.08. 국제대학생 자율주행 경진대회 세계전기차협의회 회장상 – 금상\n2022.12.09. HL만도&amp;HL Klemove 자율주행모빌리티 경진대회 HL만도(주) 대표이사상 – 최우수상\n\n\n\nconst lighturl = &#039;https://wakatime.com/share/@parkjbdev/dfae9253-f0df-4ca5-8156-6bf03904a6db.svg&#039;\nconst darkurl = &#039;https://wakatime.com/share/@parkjbdev/625efa64-7aa7-4258-8464-b21271c72545.svg&#039;\n\nconst setJandiTheme = (theme) =&gt; {\n\tconst lightelem = document.querySelector(&#039;#waka-jandi-light&#039;)\n\tconst darkelem = document.querySelector(&#039;#waka-jandi-dark&#039;)\n\tif (theme === &#039;dark&#039;) {\n\t\tlightelem.setAttribute(&#039;style&#039;, &#039;display: none;&#039;)\n\t\tdarkelem.setAttribute(&#039;style&#039;, &#039;display: block;&#039;)\n\t} else {\n\t\tlightelem.setAttribute(&#039;style&#039;, &#039;display: block;&#039;)\n\t\tdarkelem.setAttribute(&#039;style&#039;, &#039;display: none;&#039;)\n\t}\n}\n\nsetJandiTheme(document.documentElement.getAttribute(&#039;saved-theme&#039;))\ndocument.querySelector(&#039;#darkmode-toggle&#039;).addEventListener(&#039;change&#039;, (e) =&gt; setJandiTheme(e.target.checked ? &#039;dark&#039; : &#039;light&#039;))\n"},"삽질/2024-02-네트워크-삽질기":{"title":"2024-02 네트워크 삽질기","links":[],"tags":["linux"],"content":"debian bullseye에서 bookworm으로 업그레이드 한 후에, package dependency가 꼬이는 바람에 삭제하고 설치하는 과정에서 networking 관련된 서비스가 삭제되어 문제가 생긴듯하다.\n처음에는 서버가 연결이 안돼서 아예 안켜진줄 알았으나.. 알고보니 서버는 켜져있었고, 네트워크가 올바르게 로딩되지 않아서 접속이 안됐던것이다.\n그래서 직접 서버실가서 해결해야겠구나.. 싶었던 와중에 교수님께서 ipmitool을 이용해서 서버에 접속하는 방법을 알려주셨다. (당시 제주도였다..)\nipmitool -U &lt;username&gt; -P &lt;password&gt; -I &lt;interface&gt; -H &lt;address&gt; &lt;command&gt;\nMAN: https://linux.die.net/man/1/ipmitool\nIPMI? §\nIPMI는 Intelligent Platform Management Interface의 약자\n하드웨어를 원격으로 관리하는데에 사용되는 인터페이스\n그래서 &lt;command&gt;를 이용해서 서버를 켜고 끄거나(power or chassis), 서버 화면에 표시되는 내용을 원격으로 보는 (sol (serial over lan)) 등의 역할을 수행할 수 있다.\n문제해결 §\n\n우선 다음과 같이 ip a로 확인한 mir4랑 똑같이 세팅을 맞추니 간신히 ssh는 붙었다.\n\nsudo ip address add &lt;ip&gt; dev ibp94s0 brd &lt;ip&gt;\nsudo ip address add &lt;ip&gt; dev eno1 brd &lt;ip&gt;\nsudo brctl addbr br0\nsudo ip address add &lt;bridge ip&gt; dev br0 brd &lt;ip&gt;\nsudo ip link set dev ibp94s0 down\nsudo ip link set dev eno1 down\nsudo ip link set dev ibp94s0 up\nsudo ip link set dev eno1 up\n\n\nsudo apt --fix-broken install 에서 깨진 의존성들을 확인하고 직접 packages.debian.org 에서 wget 으로 다운로드하고 sftp로 보낸뒤에 sudo dpkg -i &lt;package&gt;.deb 로 설치\nnetworking.service 파일이 없어서.. mir4 세팅보고 직접 만들어서 넣어줌\nifupdown2를 alfa 서버에서 wget 명령을 이용해서 다운로드하고 sftp로 보낸뒤에 sudo dpkg -i &lt;package&gt;.deb 로 설치\nping 8.8.8.8 은 되는데 ping google.com은 안되는걸 보고, DNS 세팅이 안됐구나 확인.. systemd-networkd-wait-online.service 실행할때 --any 옵션 붙여줌.. (sudo systemctl edit --full systemd-networkd-wait-online.service) + sudo apt install resolvconf\n/share 폴더 마운트 안돼서 sudo mount -t nfs &lt;ip&gt;:/share /share로 직접 마운트하려 하니 nfs 관련 유틸 없음을 확인.. sudo apt install nfs-common로 설치하니 잘 마운팅됨\napparmor.service dmesg에서 계속 fail 떠서 찾아보니,, snapd가 지워짐.. 마찬가지로 sudo apt install snapd\n\n된당!"},"삽질/OpenCV-on-mac":{"title":"[OpenCV] Xcode OpenCV 설치 및 세팅","links":[],"tags":[],"content":"\nM1맥 기준으로 작성되었습니다. homebrew 경로는 본인 맥에 맞게 바꿔서 넣기를\n\nOpenCV 설치 §\nbrew install opencv\nDependency들 많아서 조금 걸림\nOpenCV Library &amp; Header 추가 §\nHeader &amp; Library 추가 §\n\nTargets - Build Settings에서 다음과 같이 설정\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting경로Library Search Path/opt/homebrew/Cellar/opencv/버전명/libHeader Search Path/opt/homebrew/Cellar/opencv/버전명/include/opencv4\nDisable Library Validation §\n\nDisable Library Validation 항목 체크해줄것\n이거 안하면 라이브러리 못불러온다고 에러남\n\n카메라 쓰면 그 밑에 Resource Access에서 Camera도 켜줄것!! Info.plist 만들고 할 필요 없습니다\n\nOpenCV pkg-config 플래그 확인 &amp; 추가 §\n$ pkg-config --cflags --libs /opt/homebrew/Cellar/opencv/버전명/lib/pkgconfig/opencv4.pc\n전 이렇게 나왔음\n-I/opt/homebrew/opt/opencv/include/opencv4 -L/opt/homebrew/opt/opencv/lib -lopencv_gapi -lopencv_stitching -lopencv_alphamat -lopencv_aruco -lopencv_barcode -lopencv_bgsegm -lopencv_bioinspired -lopencv_ccalib -lopencv_dnn_objdetect -lopencv_dnn_superres -lopencv_dpm -lopencv_face -lopencv_freetype -lopencv_fuzzy -lopencv_hfs -lopencv_img_hash -lopencv_intensity_transform -lopencv_line_descriptor -lopencv_mcc -lopencv_quality -lopencv_rapid -lopencv_reg -lopencv_rgbd -lopencv_saliency -lopencv_sfm -lopencv_stereo -lopencv_structured_light -lopencv_phase_unwrapping -lopencv_superres -lopencv_optflow -lopencv_surface_matching -lopencv_tracking -lopencv_highgui -lopencv_datasets -lopencv_text -lopencv_plot -lopencv_videostab -lopencv_videoio -lopencv_viz -lopencv_wechat_qrcode -lopencv_xfeatures2d -lopencv_shape -lopencv_ml -lopencv_ximgproc -lopencv_video -lopencv_xobjdetect -lopencv_objdetect -lopencv_calib3d -lopencv_imgcodecs -lopencv_features2d -lopencv_dnn -lopencv_flann -lopencv_xphoto -lopencv_photo -lopencv_imgproc -lopencv_core\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSetting경로Other Linker Flags위에 저거 복붙하기\nTest §\n코드는 https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html 에서 베껴옴\ndevideID는 적당히 바꿔가면서 올바르게 넣어보도록 한다\n전 1번 나옴\n#include &lt;opencv2/core.hpp&gt;\n#include &lt;opencv2/videoio.hpp&gt;\n#include &lt;opencv2/highgui.hpp&gt;\n#include &lt;iostream&gt;\n \nusing namespace cv;\nusing namespace std;\nint main(int, char**)\n{\n    Mat frame;\n    //--- INITIALIZE VIDEOCAPTURE\n    VideoCapture cap;\n    // open the default camera using default API\n    // cap.open(0);\n    // OR advance usage: select any API backend\n    int deviceID = 1;             // 0 = open default camera\n    int apiID = CAP_ANY;      // 0 = autodetect default API\n    // open selected camera using selected API\n    cap.open(deviceID, apiID);\n    // check if we succeeded\n    if (!cap.isOpened()) {\n        cerr &lt;&lt; &quot;ERROR! Unable to open camera\\n&quot;;\n        return -1;\n    }\n    //--- GRAB AND WRITE LOOP\n    cout &lt;&lt; &quot;Start grabbing&quot; &lt;&lt; endl\n        &lt;&lt; &quot;Press any key to terminate&quot; &lt;&lt; endl;\n    for (;;)\n    {\n        // wait for a new frame from camera and store it into &#039;frame&#039;\n        cap.read(frame);\n        // check if we succeeded\n        if (frame.empty()) {\n            cerr &lt;&lt; &quot;ERROR! blank frame grabbed\\n&quot;;\n            break;\n        }\n        // show live and wait for a key with timeout long enough to show images\n        imshow(&quot;Live&quot;, frame);\n        if (waitKey(5) &gt;= 0)\n            break;\n    }\n    // the camera will be deinitialized automatically in VideoCapture destructor\n    return 0;\n}\n \n잘된다!"},"삽질/Rosetta+Conda-Env-Setting":{"title":"[Conda] Rosetta + Conda Env 세팅","links":[],"tags":[],"content":"CONDA_SUBDIR=osx-64 conda create -n &lt;콘다환경이름&gt; python=&lt;파이썬 버전&gt;\nconda activate &lt;콘다환경이름&gt;\n# 확인 &amp; 환경변수 세팅\npython -c &quot;import platform;print(platform.machine())&quot;\nconda env config vars set CONDA_SUBDIR=osx-64  # make sure that conda commands in this environment use intel packages\n# Re-Activate Conda Environment\nconda deactivate &lt;콘다환경이름&gt;\nconda activate &lt;콘다환경이름&gt;\n# Check\necho &quot;CONDA_SUBDIR: $CONDA_SUBDIR&quot;\nhttps://github.com/conda-forge/miniforge/issues/165\n생각보다 간단하게된다..!"},"삽질/Rosetta+Conda-ROS-Setting":{"title":"[ROS] Rosetta + Conda로 ROS 세팅","links":[],"tags":[],"content":"Robostack 이용하면 애플실리콘 기반 맥에서도 ROS사용이 가능하다!\n그런데 rosbridge-server 같은 패키지들이 osx-64로만 제공이 되어 직접빌드를 하여 설치해야 됐다. (이 방법이 익숙하다면 arm64 환경으로 하는것이 더 좋을 것 같다..!)\n그런데 최근에 Rosetta를 이용한 해결법을 발견하여 공유하고자 한다😊\n참고: https://velog.io/@parkjbdev/Rosetta-Conda-Env-세팅\nROS1 (Noetic) §\nhttps://github.com/RoboStack/ros-noetic\n# if you don&#039;t have mamba yet, install it first in the base environment (not needed when using mambaforge):\nconda install mamba -c conda-forge\n \n# Create ros1 conda environment on osx-64\nCONDA_SUBDIR=osx-64 conda create -n ros1 python=3.9\n \n# 확인 &amp; 환경변수 세팅\npython -c &quot;import platform;print(platform.machine())&quot;\nconda env config vars set CONDA_SUBDIR=osx-64\n \n# Re-Activate Conda Environment\nconda deactivate ros1\nconda activate ros1\n \n# Check if config var is setted\necho &quot;CONDA_SUBDIR: $CONDA_SUBDIR&quot;\n \nmamba install ros-noetic-desktop-full -c robostack -c robostack-experimental -c conda-forge --no-channel-priority --override-channels\n \n# optionally, install some compiler packages if you want to e.g. build packages in a catkin_ws:\nmamba install compilers cmake pkg-config make ninja\n \n# on linux and osx (but not Windows) you might want to:\nmamba install catkin_tools\n \nconda deactivate\nconda activate robostackenv\n \n# if you want to use rosdep, also do:\nmamba install rosdep\nrosdep init  # note: do not use sudo!\nrosdep update\n필요한 패키지들이 있다면 여기서 검색해보자 (ex. ros-noetic-rosbridge-server)\nhttps://anaconda.org/search?q=rosbridge\nROS2 (Galactic) §\nhttps://github.com/RoboStack/ros-galactic\n사소한 팁 §\nros conda 환경에서 ls 할때 색깔이 안나왔는데, coreutils가 설치되면서 시스템의 ls보다 우선하여 실행되는듯하다. 나는 그냥 $CONDA_PREFIX/bin에서 ls파일을 지워버렸다. (coreutils의 ls와 맥의 ls가 조금 다른면이 있지만 대부분의 상황에선 잘돌아갈것으로 생각한다)"},"삽질/index":{"title":"🚧 삽질기","links":[],"tags":[],"content":""}}